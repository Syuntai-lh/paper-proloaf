{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../source/fc_evaluate.py -s opsd_24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "reading csv...\n",
      "done\n",
      "scaling data...\n",
      "done\n",
      "loading input data...\n",
      "Done\n",
      "timesteps 43654\n",
      "num_features1 5\n",
      "num_features2 43\n",
      "targets: 1\n",
      "history_horizon 147\n",
      "forecast_horizon 24\n",
      "load net...\n",
      "Done.\n",
      "\n",
      "\n",
      "timestep:  136\n",
      "create saliency maps...\n",
      "epoch  0 / 1000 ...    loss: 2.0713295936584473\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 14:16:23,790]\u001b[0m Trial 0 finished with value: 1.3776804208755493 and parameters: {'learning rate': 0.05265001953414389, 'mask initialisation value': 0.4256140659214994, 'lambda1': 0.0782795164299509}. Best is trial 0 with value: 1.3776804208755493.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 4.192807674407959\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 14:16:39,032]\u001b[0m Trial 1 finished with value: 0.8207290768623352 and parameters: {'learning rate': 0.024794135809443642, 'mask initialisation value': 0.7805029427667327, 'lambda1': 0.08986192278046917}. Best is trial 1 with value: 0.8207290768623352.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.3167996406555176\n",
      "\u001b[32m[I 2021-08-11 14:20:40,429]\u001b[0m Trial 2 finished with value: 0.2693997621536255 and parameters: {'learning rate': 8.308785697886462e-06, 'mask initialisation value': 0.026588246573235774, 'lambda1': 0.09871115566396667}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.5926849246025085\n",
      "\u001b[32m[I 2021-08-11 14:24:41,027]\u001b[0m Trial 3 finished with value: 0.5139119625091553 and parameters: {'learning rate': 6.007083574774553e-05, 'mask initialisation value': 0.3829349602908806, 'lambda1': 0.021513734637138817}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.1386929750442505\n",
      "\u001b[32m[I 2021-08-11 14:28:41,720]\u001b[0m Trial 4 finished with value: 0.2697843909263611 and parameters: {'learning rate': 0.00016479687458785593, 'mask initialisation value': 0.1830861800702982, 'lambda1': 0.09238750184153152}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.8610941171646118\n",
      "\u001b[32m[I 2021-08-11 14:32:42,078]\u001b[0m Trial 5 finished with value: 1.7850733995437622 and parameters: {'learning rate': 1.407504051065571e-05, 'mask initialisation value': 0.3157972114046935, 'lambda1': 0.09331192429579704}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.490385890007019\n",
      "\u001b[32m[I 2021-08-11 14:36:42,835]\u001b[0m Trial 6 finished with value: 1.4134786128997803 and parameters: {'learning rate': 2.185649003607209e-05, 'mask initialisation value': 0.38395156010162046, 'lambda1': 0.0609347543633099}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.5688003301620483\n",
      "\u001b[32m[I 2021-08-11 14:40:43,513]\u001b[0m Trial 7 finished with value: 0.48622435331344604 and parameters: {'learning rate': 0.00019641182160364903, 'mask initialisation value': 0.253542924414909, 'lambda1': 0.09609667607840255}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 3.156212329864502\n",
      "\u001b[32m[I 2021-08-11 14:44:56,763]\u001b[0m Trial 8 finished with value: 3.026057243347168 and parameters: {'learning rate': 3.384561293465538e-05, 'mask initialisation value': 0.7905348438135322, 'lambda1': 0.06662267490564691}. Best is trial 2 with value: 0.2693997621536255.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.1996309608221054\n",
      "\u001b[32m[I 2021-08-11 14:48:54,904]\u001b[0m Trial 9 finished with value: 0.17995817959308624 and parameters: {'learning rate': 1.615092408175366e-05, 'mask initialisation value': 0.03121495225286275, 'lambda1': 0.021098386808106186}. Best is trial 9 with value: 0.17995817959308624.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.16484156250953674\n",
      "\u001b[32m[I 2021-08-11 14:52:52,851]\u001b[0m Trial 10 finished with value: 0.1643068790435791 and parameters: {'learning rate': 1.0500146546326084e-06, 'mask initialisation value': 0.019725953147229806, 'lambda1': 0.002098972692422915}. Best is trial 10 with value: 0.1643068790435791.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.1678127497434616\n",
      "\u001b[32m[I 2021-08-11 14:56:50,894]\u001b[0m Trial 11 finished with value: 0.16639509797096252 and parameters: {'learning rate': 2.4748471398317355e-06, 'mask initialisation value': 0.029308130374805914, 'lambda1': 0.003974153992188381}. Best is trial 10 with value: 0.1643068790435791.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.17429223656654358\n",
      "\u001b[32m[I 2021-08-11 15:00:48,977]\u001b[0m Trial 12 finished with value: 0.1736484169960022 and parameters: {'learning rate': 1.0871660463826772e-06, 'mask initialisation value': 0.1031672246658204, 'lambda1': 0.004079276710427023}. Best is trial 10 with value: 0.1643068790435791.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.0696905180811882\n",
      "\u001b[32m[I 2021-08-11 15:04:47,055]\u001b[0m Trial 13 finished with value: 0.06891579926013947 and parameters: {'learning rate': 1.4706303190634836e-06, 'mask initialisation value': 0.6036006095384566, 'lambda1': 3.552668485738968e-05}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.2136428356170654\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 15:06:07,624]\u001b[0m Trial 14 finished with value: 0.2218257635831833 and parameters: {'learning rate': 0.0021932120667923563, 'mask initialisation value': 0.5847727092057268, 'lambda1': 0.03296974971434726}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 2.1463310718536377\n",
      "\u001b[32m[I 2021-08-11 15:10:05,227]\u001b[0m Trial 15 finished with value: 2.144055128097534 and parameters: {'learning rate': 1.0362976226513073e-06, 'mask initialisation value': 0.973282397066201, 'lambda1': 0.03714727632893865}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.14544695615768433\n",
      "\u001b[32m[I 2021-08-11 15:14:04,945]\u001b[0m Trial 16 finished with value: 10000241664.0 and parameters: {'learning rate': 0.0015437920759371344, 'mask initialisation value': 0.5702066551189358, 'lambda1': 0.0021144740702585697}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.5861203670501709\n",
      "\u001b[32m[I 2021-08-11 15:18:02,990]\u001b[0m Trial 17 finished with value: 0.582878053188324 and parameters: {'learning rate': 3.1181031276001883e-06, 'mask initialisation value': 0.6803872006368704, 'lambda1': 0.013169385932669284}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 2.497627019882202\n",
      "\u001b[32m[I 2021-08-11 15:22:01,297]\u001b[0m Trial 18 finished with value: 2.487481117248535 and parameters: {'learning rate': 3.796428118090935e-06, 'mask initialisation value': 0.9288486023773144, 'lambda1': 0.04516763046632849}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.5241085290908813\n",
      "\u001b[32m[I 2021-08-11 15:25:59,528]\u001b[0m Trial 19 finished with value: 0.5229957103729248 and parameters: {'learning rate': 1.0147746624510116e-06, 'mask initialisation value': 0.4952688469991374, 'lambda1': 0.014918074381018102}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.4982953071594238\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 15:29:33,595]\u001b[0m Trial 20 finished with value: 60642.77734375 and parameters: {'learning rate': 0.0009628577639292285, 'mask initialisation value': 0.7172502056973771, 'lambda1': 0.03411118433573385}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.1436631679534912\n",
      "\u001b[32m[I 2021-08-11 15:33:56,494]\u001b[0m Trial 21 finished with value: 0.14239703118801117 and parameters: {'learning rate': 2.715196769170284e-06, 'mask initialisation value': 0.15098298261297208, 'lambda1': 0.0002060219343282682}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.1430431604385376\n",
      "\u001b[32m[I 2021-08-11 15:38:08,565]\u001b[0m Trial 22 finished with value: 0.14102211594581604 and parameters: {'learning rate': 4.378286855366778e-06, 'mask initialisation value': 0.16512847425831662, 'lambda1': 0.0003554667551488796}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.24549651145935059\n",
      "\u001b[32m[I 2021-08-11 15:42:08,216]\u001b[0m Trial 23 finished with value: 0.24091462790966034 and parameters: {'learning rate': 5.111924468370322e-06, 'mask initialisation value': 0.1561728245991143, 'lambda1': 0.011296342943317798}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.44049394130706787\n",
      "\u001b[32m[I 2021-08-11 15:46:06,656]\u001b[0m Trial 24 finished with value: 0.3236374258995056 and parameters: {'learning rate': 8.287023052209733e-05, 'mask initialisation value': 0.21113980677694824, 'lambda1': 0.024639563863474954}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 / 1000 ...    loss: 0.36933717131614685\n",
      "\u001b[32m[I 2021-08-11 15:50:05,434]\u001b[0m Trial 25 finished with value: 0.36715149879455566 and parameters: {'learning rate': 2.55858356129912e-06, 'mask initialisation value': 0.5059793709797, 'lambda1': 0.009497267544068256}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.11727282404899597\n",
      "\u001b[32m[I 2021-08-11 15:54:04,069]\u001b[0m Trial 26 finished with value: 0.11350100487470627 and parameters: {'learning rate': 8.026035111964894e-06, 'mask initialisation value': 0.31379804657990035, 'lambda1': 7.515519785925721e-05}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.5333986282348633\n",
      "\u001b[32m[I 2021-08-11 15:58:03,174]\u001b[0m Trial 27 finished with value: 0.5202109217643738 and parameters: {'learning rate': 8.25837107964195e-06, 'mask initialisation value': 0.2685607238307486, 'lambda1': 0.025789166466135688}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.2854330837726593\n",
      "\u001b[32m[I 2021-08-11 16:02:01,660]\u001b[0m Trial 28 finished with value: 0.2545934021472931 and parameters: {'learning rate': 4.187819818074436e-05, 'mask initialisation value': 0.324721929043547, 'lambda1': 0.008907180611267431}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.6169940233230591\n",
      "\u001b[32m[I 2021-08-11 16:05:59,623]\u001b[0m Trial 29 finished with value: 0.6060371994972229 and parameters: {'learning rate': 8.726512894363337e-06, 'mask initialisation value': 0.4789383472064326, 'lambda1': 0.018606446859885595}. Best is trial 13 with value: 0.06891579926013947.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.07586159557104111\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:07:09,635]\u001b[0m Trial 30 finished with value: 0.008433666080236435 and parameters: {'learning rate': 0.007222664200174258, 'mask initialisation value': 0.6096355240528885, 'lambda1': 0.0002343088571464897}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.2941264808177948\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:07:35,772]\u001b[0m Trial 31 finished with value: 7925045.0 and parameters: {'learning rate': 0.018277249606436313, 'mask initialisation value': 0.6162456218496887, 'lambda1': 0.006241629457444526}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.05600437894463539\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:09:39,443]\u001b[0m Trial 32 finished with value: 0.015275626443326473 and parameters: {'learning rate': 0.007060826259347664, 'mask initialisation value': 0.8351124004859996, 'lambda1': 0.0005511704845112615}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 4.016119956970215\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:10:08,530]\u001b[0m Trial 33 finished with value: 847957760.0 and parameters: {'learning rate': 0.007713067417096996, 'mask initialisation value': 0.8248190670627668, 'lambda1': 0.08157434990675864}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.9272606372833252\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:10:42,073]\u001b[0m Trial 34 finished with value: 0.7309214472770691 and parameters: {'learning rate': 0.09832528082044772, 'mask initialisation value': 0.8655464657268332, 'lambda1': 0.017627345653630496}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.40642115473747253\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:11:39,098]\u001b[0m Trial 35 finished with value: 2214024.0 and parameters: {'learning rate': 0.0060464754460840524, 'mask initialisation value': 0.6770373930834969, 'lambda1': 0.00873940446346852}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.07615026086568832\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:12:52,045]\u001b[0m Trial 36 finished with value: 10041199616.0 and parameters: {'learning rate': 0.03599005389783922, 'mask initialisation value': 0.7018217511010852, 'lambda1': 0.0005887868420386525}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.8076963424682617\n",
      "\u001b[32m[I 2021-08-11 16:16:50,085]\u001b[0m Trial 37 finished with value: 0.18721871078014374 and parameters: {'learning rate': 0.0005766052549787313, 'mask initialisation value': 0.4278304832743528, 'lambda1': 0.028026430627325998}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 2.0369887351989746\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:17:07,715]\u001b[0m Trial 38 finished with value: 935270848.0 and parameters: {'learning rate': 0.00965101114546523, 'mask initialisation value': 0.5510787797134872, 'lambda1': 0.06003644481731301}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.0425446443259716\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:18:28,914]\u001b[0m Trial 39 finished with value: 10000876544.0 and parameters: {'learning rate': 0.003493107301465276, 'mask initialisation value': 0.7577023737912854, 'lambda1': 1.0691886504740554e-05}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.6214491724967957\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:18:51,416]\u001b[0m Trial 40 finished with value: 0.5146358013153076 and parameters: {'learning rate': 0.09816782219504057, 'mask initialisation value': 0.6370593058561638, 'lambda1': 0.014804807404502865}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.2330433577299118\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:19:20,118]\u001b[0m Trial 41 finished with value: 0.11395673453807831 and parameters: {'learning rate': 0.0154619928722933, 'mask initialisation value': 0.34579474767507556, 'lambda1': 0.005974078919121948}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.22509270906448364\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:19:52,945]\u001b[0m Trial 42 finished with value: 0.10426102578639984 and parameters: {'learning rate': 0.014811977838292504, 'mask initialisation value': 0.38417282984757206, 'lambda1': 0.0053000001089931565}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.11081913113594055\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:20:55,063]\u001b[0m Trial 43 finished with value: 0.08364735543727875 and parameters: {'learning rate': 0.047826570155563373, 'mask initialisation value': 0.412796724142778, 'lambda1': 0.0004486572747695335}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.2525944113731384\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:21:17,589]\u001b[0m Trial 44 finished with value: 0.1372319459915161 and parameters: {'learning rate': 0.03555041374717851, 'mask initialisation value': 0.4112103172680105, 'lambda1': 0.006260282383741201}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.41585177183151245\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:21:34,233]\u001b[0m Trial 45 finished with value: 0.33337128162384033 and parameters: {'learning rate': 0.06350379475706852, 'mask initialisation value': 0.446514266020307, 'lambda1': 0.012153112542578375}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.6972138285636902\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:22:24,147]\u001b[0m Trial 46 finished with value: 0.20108965039253235 and parameters: {'learning rate': 0.004263413524363418, 'mask initialisation value': 0.5325320100659363, 'lambda1': 0.019556818717746477}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.23739328980445862\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:22:34,154]\u001b[0m Trial 47 finished with value: 17489381376.0 and parameters: {'learning rate': 0.05488662161373057, 'mask initialisation value': 0.3946617105193996, 'lambda1': 0.005757878937376025}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.20721182227134705\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:23:05,908]\u001b[0m Trial 48 finished with value: 10031827968.0 and parameters: {'learning rate': 0.012621260717486385, 'mask initialisation value': 0.619021142835849, 'lambda1': 0.003856147352101201}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 2.4499213695526123\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:23:21,235]\u001b[0m Trial 49 finished with value: 0.5134260058403015 and parameters: {'learning rate': 0.025853180710539842, 'mask initialisation value': 0.8807898066517393, 'lambda1': 0.04655687588294169}. Best is trial 30 with value: 0.008433666080236435.\u001b[0m\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all plots saved in /home/jupyter/profiles/ggu/proloaf/./oracles/interpretation/opsd_24_LSTM_gnll/plots/\n",
      "Elapsed time:  7628.079124774784\n",
      "\n",
      "\n",
      "timestep:  304\n",
      "create saliency maps...\n",
      "epoch  0 / 1000 ...    loss: 0.612523078918457\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:25:49,621]\u001b[0m Trial 0 finished with value: 0.24612858891487122 and parameters: {'learning rate': 0.00012768936744069848, 'mask initialisation value': 0.07295547692992188, 'lambda1': 0.09095350927999149}. Best is trial 0 with value: 0.24612858891487122.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.8211655616760254\n",
      "\u001b[32m[I 2021-08-11 16:29:49,777]\u001b[0m Trial 1 finished with value: 1.3546161651611328 and parameters: {'learning rate': 0.00011931590480180465, 'mask initialisation value': 0.4209507286536285, 'lambda1': 0.06706125681534235}. Best is trial 0 with value: 0.24612858891487122.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 2.1249325275421143\n",
      "\u001b[32m[I 2021-08-11 16:33:48,080]\u001b[0m Trial 2 finished with value: 2.055116891860962 and parameters: {'learning rate': 1.2655444968772371e-05, 'mask initialisation value': 0.35411946112572124, 'lambda1': 0.09350696889024654}. Best is trial 0 with value: 0.24612858891487122.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.7114307880401611\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:34:00,060]\u001b[0m Trial 3 finished with value: 0.9235844016075134 and parameters: {'learning rate': 0.026674134177324175, 'mask initialisation value': 0.3204377125110768, 'lambda1': 0.08117187204467424}. Best is trial 0 with value: 0.24612858891487122.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 2.2238271236419678\n",
      "\u001b[32m[I 2021-08-11 16:37:58,784]\u001b[0m Trial 4 finished with value: 1.9100228548049927 and parameters: {'learning rate': 0.00012538974377876796, 'mask initialisation value': 0.8474426698761373, 'lambda1': 0.04347119073505628}. Best is trial 0 with value: 0.24612858891487122.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 1.8006473779678345\n",
      "\u001b[32m[I 2021-08-11 16:41:58,520]\u001b[0m Trial 5 finished with value: 1.7924867868423462 and parameters: {'learning rate': 2.8214305481173006e-06, 'mask initialisation value': 0.6237368375182553, 'lambda1': 0.04598633947617258}. Best is trial 0 with value: 0.24612858891487122.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.20182642340660095\n",
      "\u001b[32m[I 2021-08-11 16:45:57,122]\u001b[0m Trial 6 finished with value: 0.18974819779396057 and parameters: {'learning rate': 1.4558087785279087e-05, 'mask initialisation value': 0.5180669895372845, 'lambda1': 0.0024341498337243973}. Best is trial 6 with value: 0.18974819779396057.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.27756354212760925\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:46:18,655]\u001b[0m Trial 7 finished with value: 0.23590940237045288 and parameters: {'learning rate': 0.00033965276239760313, 'mask initialisation value': 0.018959947054842052, 'lambda1': 0.04317658050482313}. Best is trial 6 with value: 0.18974819779396057.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 3.4842705726623535\n",
      "\u001b[32m[I 2021-08-11 16:50:17,425]\u001b[0m Trial 8 finished with value: 3.4611241817474365 and parameters: {'learning rate': 5.952617116281904e-06, 'mask initialisation value': 0.9046032850416748, 'lambda1': 0.06453974145092373}. Best is trial 6 with value: 0.18974819779396057.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.6587287187576294\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:50:40,151]\u001b[0m Trial 9 finished with value: 10033803264.0 and parameters: {'learning rate': 0.0623313565226586, 'mask initialisation value': 0.6498599596031562, 'lambda1': 0.014646218047420778}. Best is trial 6 with value: 0.18974819779396057.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.19255807995796204\n",
      "\u001b[32m[I 2021-08-11 16:54:38,914]\u001b[0m Trial 10 finished with value: 0.013328511267900467 and parameters: {'learning rate': 0.001741895431363297, 'mask initialisation value': 0.22460429173832958, 'lambda1': 0.0001482564157566273}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.21776241064071655\n",
      "\u001b[32m[I 2021-08-11 16:58:38,057]\u001b[0m Trial 11 finished with value: 0.04575171694159508 and parameters: {'learning rate': 0.003123669312333292, 'mask initialisation value': 0.1804840320790626, 'lambda1': 0.001723184941980681}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.3820984959602356\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 16:58:50,859]\u001b[0m Trial 12 finished with value: 97652392.0 and parameters: {'learning rate': 0.005046234655348062, 'mask initialisation value': 0.1913149515646323, 'lambda1': 0.016313472203711155}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.2676818370819092\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 17:01:22,028]\u001b[0m Trial 13 finished with value: 0.10864374041557312 and parameters: {'learning rate': 0.002422844194202521, 'mask initialisation value': 0.18578883431088972, 'lambda1': 0.006303776873683977}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.4831336438655853\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 17:03:18,161]\u001b[0m Trial 14 finished with value: 0.2261917144060135 and parameters: {'learning rate': 0.0024026836526498474, 'mask initialisation value': 0.18626289903374676, 'lambda1': 0.0258232484809182}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.2848889231681824\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 17:03:25,567]\u001b[0m Trial 15 finished with value: 0.29071563482284546 and parameters: {'learning rate': 0.010582505195198768, 'mask initialisation value': 0.034357851926238636, 'lambda1': 0.02874991601657589}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.21302857995033264\n",
      "\u001b[32m[I 2021-08-11 17:07:31,260]\u001b[0m Trial 16 finished with value: 0.05395113676786423 and parameters: {'learning rate': 0.0007644879098857542, 'mask initialisation value': 0.2726438948136315, 'lambda1': 0.0020004922118361085}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.44711989164352417\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-11 17:07:57,251]\u001b[0m Trial 17 finished with value: 0.9092088937759399 and parameters: {'learning rate': 0.08997415092306492, 'mask initialisation value': 0.13619434474161018, 'lambda1': 0.029665114878884086}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.5338163375854492\n",
      "\u001b[32m[I 2021-08-11 17:11:56,154]\u001b[0m Trial 18 finished with value: 0.17876452207565308 and parameters: {'learning rate': 0.0007849431379353544, 'mask initialisation value': 0.459991968149903, 'lambda1': 0.014440974296035535}. Best is trial 10 with value: 0.013328511267900467.\u001b[0m\n",
      "epoch  0 / 1000 ...    loss: 0.18566647171974182\n"
     ]
    }
   ],
   "source": [
    "!python3 ../source/fc_interpret.py -s opsd_24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perturbated prediction evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reserver",
   "language": "python",
   "name": "reserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
