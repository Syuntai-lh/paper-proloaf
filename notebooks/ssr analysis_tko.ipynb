{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opsd forecast horizon 24h one hot encoded aux features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "reading csv...\n",
      "done\n",
      "scaling data...\n",
      "done\n",
      "loading input data...\n",
      "Done\n",
      "timesteps 43673\n",
      "num_features1 1\n",
      "num_features2 45\n",
      "targets: 1\n",
      "history_horizon 128\n",
      "forecast_horizon 24\n",
      "load net...\n",
      "Done.\n",
      "\n",
      "\n",
      "timestep:  0\n",
      "create saliency maps...\n",
      "epoch  0 / 10000 ...    loss: 23.804912567138672\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-05 21:16:10,590]\u001b[0m Trial 0 finished with value: 1.1141645908355713 and parameters: {'learning rate': 0.004680178802753361, 'mask initialisation value': 0.8222498374195257, 'lambda1': 0.6538628015628658}. Best is trial 0 with value: 1.1141645908355713.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 20.324474334716797\n",
      "epoch  1000 / 10000 ...    loss: 17.515941619873047\n",
      "epoch  2000 / 10000 ...    loss: 14.705228805541992\n",
      "epoch  3000 / 10000 ...    loss: 11.893404006958008\n",
      "epoch  4000 / 10000 ...    loss: 9.080665588378906\n",
      "epoch  5000 / 10000 ...    loss: 6.267108917236328\n",
      "epoch  6000 / 10000 ...    loss: 3.453221321105957\n",
      "epoch  7000 / 10000 ...    loss: 0.6399039030075073\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-05 21:44:55,711]\u001b[0m Trial 1 finished with value: 0.319433331489563 and parameters: {'learning rate': 9.712398923538507e-05, 'mask initialisation value': 0.6927679639334181, 'lambda1': 0.6611090360904062}. Best is trial 1 with value: 0.319433331489563.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 28.0871524810791\n",
      "epoch  1000 / 10000 ...    loss: 6.493650436401367\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-05 21:50:13,090]\u001b[0m Trial 2 finished with value: 0.5332803130149841 and parameters: {'learning rate': 0.0006269804355437767, 'mask initialisation value': 0.8078587937696257, 'lambda1': 0.785373498128922}. Best is trial 1 with value: 0.319433331489563.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 4.902518272399902\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-05 21:52:24,653]\u001b[0m Trial 3 finished with value: 0.3500250577926636 and parameters: {'learning rate': 0.00027835764088444243, 'mask initialisation value': 0.1468732279469821, 'lambda1': 0.7194027218305078}. Best is trial 1 with value: 0.319433331489563.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.8478143215179443\n",
      "epoch  1000 / 10000 ...    loss: 0.8094651103019714\n",
      "epoch  2000 / 10000 ...    loss: 0.7711520195007324\n",
      "epoch  3000 / 10000 ...    loss: 0.7328587174415588\n",
      "epoch  4000 / 10000 ...    loss: 0.6945799589157104\n",
      "epoch  5000 / 10000 ...    loss: 0.6563035845756531\n",
      "epoch  6000 / 10000 ...    loss: 0.6180257201194763\n",
      "epoch  7000 / 10000 ...    loss: 0.5797439813613892\n",
      "epoch  8000 / 10000 ...    loss: 0.5414673089981079\n",
      "epoch  9000 / 10000 ...    loss: 0.503193199634552\n",
      "\u001b[32m[I 2021-08-05 22:32:48,350]\u001b[0m Trial 4 finished with value: 0.4649673104286194 and parameters: {'learning rate': 3.6247372865671184e-06, 'mask initialisation value': 0.05472967689719732, 'lambda1': 0.24451884579029903}. Best is trial 1 with value: 0.319433331489563.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.8286107182502747\n",
      "epoch  1000 / 10000 ...    loss: 0.787156879901886\n",
      "epoch  2000 / 10000 ...    loss: 0.7465136647224426\n",
      "epoch  3000 / 10000 ...    loss: 0.7066574096679688\n",
      "epoch  4000 / 10000 ...    loss: 0.6675882935523987\n",
      "epoch  5000 / 10000 ...    loss: 0.6293367147445679\n",
      "epoch  6000 / 10000 ...    loss: 0.5919199585914612\n",
      "epoch  7000 / 10000 ...    loss: 0.5553691387176514\n",
      "epoch  8000 / 10000 ...    loss: 0.5197123289108276\n",
      "epoch  9000 / 10000 ...    loss: 0.48500314354896545\n",
      "\u001b[32m[I 2021-08-05 23:13:12,882]\u001b[0m Trial 5 finished with value: 0.45140188932418823 and parameters: {'learning rate': 1.5894227585270488e-05, 'mask initialisation value': 0.2401721148359226, 'lambda1': 0.05809408873301669}. Best is trial 1 with value: 0.319433331489563.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 39.68032455444336\n",
      "epoch  1000 / 10000 ...    loss: 39.546844482421875\n",
      "epoch  2000 / 10000 ...    loss: 39.41360092163086\n",
      "epoch  3000 / 10000 ...    loss: 39.28067398071289\n",
      "epoch  4000 / 10000 ...    loss: 39.14752197265625\n",
      "epoch  5000 / 10000 ...    loss: 39.01437759399414\n",
      "epoch  6000 / 10000 ...    loss: 38.88096618652344\n",
      "epoch  7000 / 10000 ...    loss: 38.74781799316406\n",
      "epoch  8000 / 10000 ...    loss: 38.61463928222656\n",
      "epoch  9000 / 10000 ...    loss: 38.481727600097656\n",
      "\u001b[32m[I 2021-08-05 23:53:40,278]\u001b[0m Trial 6 finished with value: 38.348724365234375 and parameters: {'learning rate': 3.21933543535675e-06, 'mask initialisation value': 0.9517322222886776, 'lambda1': 0.9434122531799206}. Best is trial 1 with value: 0.319433331489563.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.1953489780426025\n",
      "epoch  1000 / 10000 ...    loss: 0.8778914213180542\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-05 23:59:38,384]\u001b[0m Trial 7 finished with value: 0.28842005133628845 and parameters: {'learning rate': 7.419804036874048e-05, 'mask initialisation value': 0.10846482712664551, 'lambda1': 0.40726186583882473}. Best is trial 7 with value: 0.28842005133628845.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.3409019112586975\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-05 23:59:44,479]\u001b[0m Trial 8 finished with value: 0.29325756430625916 and parameters: {'learning rate': 0.0034981087083495194, 'mask initialisation value': 0.027630366737377732, 'lambda1': 0.06380165661208803}. Best is trial 7 with value: 0.28842005133628845.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.6640398502349854\n",
      "epoch  1000 / 10000 ...    loss: 0.5792648196220398\n",
      "epoch  2000 / 10000 ...    loss: 0.5024220943450928\n",
      "epoch  3000 / 10000 ...    loss: 0.4345197081565857\n",
      "epoch  4000 / 10000 ...    loss: 0.3760235905647278\n",
      "epoch  5000 / 10000 ...    loss: 0.3273264169692993\n",
      "epoch  6000 / 10000 ...    loss: 0.29091960191726685\n",
      "epoch  7000 / 10000 ...    loss: 0.270480215549469\n",
      "epoch  8000 / 10000 ...    loss: 0.26516619324684143\n",
      "epoch  9000 / 10000 ...    loss: 0.26397785544395447\n",
      "\u001b[32m[I 2021-08-06 00:40:17,088]\u001b[0m Trial 9 finished with value: 0.26345354318618774 and parameters: {'learning rate': 5.440781161364143e-05, 'mask initialisation value': 0.355833462770934, 'lambda1': 0.030577514631492164}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 5.407800674438477\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 00:40:23,142]\u001b[0m Trial 10 finished with value: 4.901022434234619 and parameters: {'learning rate': 0.09179458496979646, 'mask initialisation value': 0.40633599216851624, 'lambda1': 0.2917613045350108}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 6.724205493927002\n",
      "epoch  1000 / 10000 ...    loss: 6.248478889465332\n",
      "epoch  2000 / 10000 ...    loss: 5.77273416519165\n",
      "epoch  3000 / 10000 ...    loss: 5.2969160079956055\n",
      "epoch  4000 / 10000 ...    loss: 4.820971488952637\n",
      "epoch  5000 / 10000 ...    loss: 4.3450541496276855\n",
      "epoch  6000 / 10000 ...    loss: 3.869143486022949\n",
      "epoch  7000 / 10000 ...    loss: 3.3932039737701416\n",
      "epoch  8000 / 10000 ...    loss: 2.9172422885894775\n",
      "epoch  9000 / 10000 ...    loss: 2.441288948059082\n",
      "\u001b[32m[I 2021-08-06 01:20:49,393]\u001b[0m Trial 11 finished with value: 1.9658308029174805 and parameters: {'learning rate': 2.683902468707013e-05, 'mask initialisation value': 0.36404515083058425, 'lambda1': 0.40683546566292156}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 5.959377765655518\n",
      "epoch  1000 / 10000 ...    loss: 5.507238864898682\n",
      "epoch  2000 / 10000 ...    loss: 5.055932998657227\n",
      "epoch  3000 / 10000 ...    loss: 4.6046142578125\n",
      "epoch  4000 / 10000 ...    loss: 4.153084754943848\n",
      "epoch  5000 / 10000 ...    loss: 3.701174259185791\n",
      "epoch  6000 / 10000 ...    loss: 3.2492730617523193\n",
      "epoch  7000 / 10000 ...    loss: 2.79713773727417\n",
      "epoch  8000 / 10000 ...    loss: 2.344874858856201\n",
      "epoch  9000 / 10000 ...    loss: 1.892653465270996\n",
      "\u001b[32m[I 2021-08-06 02:01:18,700]\u001b[0m Trial 12 finished with value: 1.4411979913711548 and parameters: {'learning rate': 4.248744451658105e-05, 'mask initialisation value': 0.5347185653812128, 'lambda1': 0.24650980179606752}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 5.702378749847412\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 02:02:39,487]\u001b[0m Trial 13 finished with value: 0.3897688388824463 and parameters: {'learning rate': 0.0008269875568582839, 'mask initialisation value': 0.2623339346470058, 'lambda1': 0.47419927217222946}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.8101100325584412\n",
      "epoch  1000 / 10000 ...    loss: 0.8082502484321594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2000 / 10000 ...    loss: 0.8063944578170776\n",
      "epoch  3000 / 10000 ...    loss: 0.804542064666748\n",
      "epoch  4000 / 10000 ...    loss: 0.8026915192604065\n",
      "epoch  5000 / 10000 ...    loss: 0.8008434176445007\n",
      "epoch  6000 / 10000 ...    loss: 0.7989970445632935\n",
      "epoch  7000 / 10000 ...    loss: 0.797152042388916\n",
      "epoch  8000 / 10000 ...    loss: 0.7953145503997803\n",
      "epoch  9000 / 10000 ...    loss: 0.793472945690155\n",
      "\u001b[32m[I 2021-08-06 02:43:03,368]\u001b[0m Trial 14 finished with value: 0.7916403412818909 and parameters: {'learning rate': 1.1379805032440768e-06, 'mask initialisation value': 0.5034080638288256, 'lambda1': 0.029916847627773562}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.2801077365875244\n",
      "epoch  1000 / 10000 ...    loss: 0.3046291172504425\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 02:47:46,595]\u001b[0m Trial 15 finished with value: 0.29211530089378357 and parameters: {'learning rate': 0.0001592883543327448, 'mask initialisation value': 0.16266676099410246, 'lambda1': 0.14599907197326073}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 6.495120525360107\n",
      "epoch  1000 / 10000 ...    loss: 6.3420329093933105\n",
      "epoch  2000 / 10000 ...    loss: 6.189004898071289\n",
      "epoch  3000 / 10000 ...    loss: 6.035983085632324\n",
      "epoch  4000 / 10000 ...    loss: 5.882898330688477\n",
      "epoch  5000 / 10000 ...    loss: 5.729811191558838\n",
      "epoch  6000 / 10000 ...    loss: 5.576733589172363\n",
      "epoch  7000 / 10000 ...    loss: 5.42366361618042\n",
      "epoch  8000 / 10000 ...    loss: 5.270586013793945\n",
      "epoch  9000 / 10000 ...    loss: 5.1174540519714355\n",
      "\u001b[32m[I 2021-08-06 03:28:19,727]\u001b[0m Trial 16 finished with value: 4.9644975662231445 and parameters: {'learning rate': 8.710192384102228e-06, 'mask initialisation value': 0.35380796701333495, 'lambda1': 0.40378333043835357}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 4.94777250289917\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 03:28:33,694]\u001b[0m Trial 17 finished with value: 0.6094138622283936 and parameters: {'learning rate': 0.002632908311117911, 'mask initialisation value': 0.10756339527447256, 'lambda1': 0.9898602094901029}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 15.929369926452637\n",
      "epoch  1000 / 10000 ...    loss: 14.08654499053955\n",
      "epoch  2000 / 10000 ...    loss: 12.242757797241211\n",
      "epoch  3000 / 10000 ...    loss: 10.397928237915039\n",
      "epoch  4000 / 10000 ...    loss: 8.552607536315918\n",
      "epoch  5000 / 10000 ...    loss: 6.706947326660156\n",
      "epoch  6000 / 10000 ...    loss: 4.861053943634033\n",
      "epoch  7000 / 10000 ...    loss: 3.0151023864746094\n",
      "epoch  8000 / 10000 ...    loss: 1.1691807508468628\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 04:02:53,165]\u001b[0m Trial 18 finished with value: 0.30218806862831116 and parameters: {'learning rate': 7.076332768809678e-05, 'mask initialisation value': 0.6007006511453052, 'lambda1': 0.5958233908222386}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 7.0199666023254395\n",
      "epoch  1000 / 10000 ...    loss: 6.880373001098633\n",
      "epoch  2000 / 10000 ...    loss: 6.740767478942871\n",
      "epoch  3000 / 10000 ...    loss: 6.6011433601379395\n",
      "epoch  4000 / 10000 ...    loss: 6.46151065826416\n",
      "epoch  5000 / 10000 ...    loss: 6.321926116943359\n",
      "epoch  6000 / 10000 ...    loss: 6.182309150695801\n",
      "epoch  7000 / 10000 ...    loss: 6.0426764488220215\n",
      "epoch  8000 / 10000 ...    loss: 5.903074264526367\n",
      "epoch  9000 / 10000 ...    loss: 5.763410568237305\n",
      "\u001b[32m[I 2021-08-06 04:43:22,356]\u001b[0m Trial 19 finished with value: 5.623942852020264 and parameters: {'learning rate': 6.05188435176751e-06, 'mask initialisation value': 0.2924430299834101, 'lambda1': 0.5279406474463149}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.6469447612762451\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 04:43:26,370]\u001b[0m Trial 20 finished with value: 2.525938034057617 and parameters: {'learning rate': 0.027105354244527074, 'mask initialisation value': 0.00997163097096021, 'lambda1': 0.8619860151832801}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.5496782064437866\n",
      "epoch  1000 / 10000 ...    loss: 0.40184324979782104\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 04:48:00,627]\u001b[0m Trial 21 finished with value: 0.28932517766952515 and parameters: {'learning rate': 0.00015820374718263859, 'mask initialisation value': 0.17556846329248738, 'lambda1': 0.17042561515500088}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.440083622932434\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 04:49:37,415]\u001b[0m Trial 22 finished with value: 36428956.0 and parameters: {'learning rate': 0.0004664966102667538, 'mask initialisation value': 0.178908089790451, 'lambda1': 0.15348037014798446}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 6.1656174659729\n",
      "epoch  1000 / 10000 ...    loss: 3.9367318153381348\n",
      "epoch  2000 / 10000 ...    loss: 1.705190658569336\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 05:00:24,176]\u001b[0m Trial 23 finished with value: 0.3074806332588196 and parameters: {'learning rate': 0.00015890867605533588, 'mask initialisation value': 0.42016336267327314, 'lambda1': 0.3231799034995102}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.9316943883895874\n",
      "epoch  1000 / 10000 ...    loss: 1.7753313779830933\n",
      "epoch  2000 / 10000 ...    loss: 1.6200650930404663\n",
      "epoch  3000 / 10000 ...    loss: 1.4655367136001587\n",
      "epoch  4000 / 10000 ...    loss: 1.3115262985229492\n",
      "epoch  5000 / 10000 ...    loss: 1.1578620672225952\n",
      "epoch  6000 / 10000 ...    loss: 1.004410743713379\n",
      "epoch  7000 / 10000 ...    loss: 0.8512367606163025\n",
      "epoch  8000 / 10000 ...    loss: 0.6987996101379395\n",
      "epoch  9000 / 10000 ...    loss: 0.5481831431388855\n",
      "\u001b[32m[I 2021-08-06 05:40:55,239]\u001b[0m Trial 24 finished with value: 0.40435171127319336 and parameters: {'learning rate': 2.683138976988523e-05, 'mask initialisation value': 0.28843501730674304, 'lambda1': 0.1358745388929305}. Best is trial 9 with value: 0.26345354318618774.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.289446622133255\n",
      "epoch  1000 / 10000 ...    loss: 81563.421875\n",
      "epoch  2000 / 10000 ...    loss: 0.2052769958972931\n",
      "epoch  3000 / 10000 ...    loss: 0.18667618930339813\n",
      "epoch  4000 / 10000 ...    loss: 0.17171522974967957\n",
      "epoch  5000 / 10000 ...    loss: 0.16176706552505493\n",
      "epoch  6000 / 10000 ...    loss: 0.15551725029945374\n",
      "epoch  7000 / 10000 ...    loss: 0.1517074704170227\n",
      "epoch  8000 / 10000 ...    loss: 0.14922362565994263\n",
      "epoch  9000 / 10000 ...    loss: 0.1475726068019867\n",
      "\u001b[32m[I 2021-08-06 06:21:38,739]\u001b[0m Trial 25 finished with value: 0.14642930030822754 and parameters: {'learning rate': 9.075691120554202e-05, 'mask initialisation value': 0.09131648503491147, 'lambda1': 0.010277359336441083}. Best is trial 25 with value: 0.14642930030822754.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.25113406777381897\n",
      "epoch  1000 / 10000 ...    loss: 0.20805349946022034\n",
      "epoch  2000 / 10000 ...    loss: 0.17582067847251892\n",
      "epoch  3000 / 10000 ...    loss: 0.1505570113658905\n",
      "epoch  4000 / 10000 ...    loss: 0.12772364914417267\n",
      "epoch  5000 / 10000 ...    loss: 0.10893911123275757\n",
      "epoch  6000 / 10000 ...    loss: 0.09487634152173996\n",
      "epoch  7000 / 10000 ...    loss: 0.08471697568893433\n",
      "epoch  8000 / 10000 ...    loss: 0.07720077037811279\n",
      "epoch  9000 / 10000 ...    loss: 0.07148607820272446\n",
      "\u001b[32m[I 2021-08-06 07:02:20,680]\u001b[0m Trial 26 finished with value: 0.06688917428255081 and parameters: {'learning rate': 6.76578357661291e-05, 'mask initialisation value': 0.09704743815786043, 'lambda1': 0.001052233229289986}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.27138185501098633\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 07:02:25,557]\u001b[0m Trial 27 finished with value: 0.2739025354385376 and parameters: {'learning rate': 0.0014188803771391233, 'mask initialisation value': 0.0015528678781409622, 'lambda1': 0.031294042567116}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.26011648774147034\n",
      "epoch  1000 / 10000 ...    loss: 0.2516760528087616\n",
      "epoch  2000 / 10000 ...    loss: 0.24354375898838043\n",
      "epoch  3000 / 10000 ...    loss: 0.23573321104049683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4000 / 10000 ...    loss: 0.22818917036056519\n",
      "epoch  5000 / 10000 ...    loss: 0.22090384364128113\n",
      "epoch  6000 / 10000 ...    loss: 0.21386905014514923\n",
      "epoch  7000 / 10000 ...    loss: 100004.3984375\n",
      "epoch  8000 / 10000 ...    loss: 0.20351830124855042\n",
      "epoch  9000 / 10000 ...    loss: 0.19906345009803772\n",
      "\u001b[32m[I 2021-08-06 07:42:58,279]\u001b[0m Trial 28 finished with value: 0.19464430212974548 and parameters: {'learning rate': 1.2095243684084947e-05, 'mask initialisation value': 0.0780263704269042, 'lambda1': 0.0026051126668394757}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.6332947611808777\n",
      "epoch  1000 / 10000 ...    loss: 0.625511109828949\n",
      "epoch  2000 / 10000 ...    loss: 0.61774742603302\n",
      "epoch  3000 / 10000 ...    loss: 0.6100157499313354\n",
      "epoch  4000 / 10000 ...    loss: 0.6023008823394775\n",
      "epoch  5000 / 10000 ...    loss: 0.5946035981178284\n",
      "epoch  6000 / 10000 ...    loss: 0.58692467212677\n",
      "epoch  7000 / 10000 ...    loss: 0.5792604684829712\n",
      "epoch  8000 / 10000 ...    loss: 0.5716112852096558\n",
      "epoch  9000 / 10000 ...    loss: 0.5639772415161133\n",
      "\u001b[32m[I 2021-08-06 08:23:37,898]\u001b[0m Trial 29 finished with value: 0.5563650131225586 and parameters: {'learning rate': 1.7785104609923112e-06, 'mask initialisation value': 0.08597170007633846, 'lambda1': 0.10111679721345346}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.3240671753883362\n",
      "epoch  1000 / 10000 ...    loss: 0.30955690145492554\n",
      "epoch  2000 / 10000 ...    loss: 0.2955796420574188\n",
      "epoch  3000 / 10000 ...    loss: 0.282013863325119\n",
      "epoch  4000 / 10000 ...    loss: 0.26908355951309204\n",
      "epoch  5000 / 10000 ...    loss: 0.25671422481536865\n",
      "epoch  6000 / 10000 ...    loss: 0.2449948787689209\n",
      "epoch  7000 / 10000 ...    loss: 0.23402921855449677\n",
      "epoch  8000 / 10000 ...    loss: 0.22382503747940063\n",
      "epoch  9000 / 10000 ...    loss: 0.21437036991119385\n",
      "\u001b[32m[I 2021-08-06 09:05:45,096]\u001b[0m Trial 30 finished with value: 0.20570339262485504 and parameters: {'learning rate': 1.5365320685282443e-05, 'mask initialisation value': 0.20471075254098542, 'lambda1': 0.011415852812382261}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.2701752781867981\n",
      "epoch  1000 / 10000 ...    loss: 0.2681322991847992\n",
      "epoch  2000 / 10000 ...    loss: 0.2666553854942322\n",
      "epoch  3000 / 10000 ...    loss: 0.2651897072792053\n",
      "epoch  4000 / 10000 ...    loss: 0.26374921202659607\n",
      "epoch  5000 / 10000 ...    loss: 0.26232120394706726\n",
      "epoch  6000 / 10000 ...    loss: 0.2608804702758789\n",
      "epoch  7000 / 10000 ...    loss: 0.25944364070892334\n",
      "epoch  8000 / 10000 ...    loss: 0.2580285966396332\n",
      "epoch  9000 / 10000 ...    loss: 0.25661301612854004\n",
      "\u001b[32m[I 2021-08-06 09:48:59,630]\u001b[0m Trial 31 finished with value: 0.2552158832550049 and parameters: {'learning rate': 1.3273413977476935e-05, 'mask initialisation value': 0.0008253708738669568, 'lambda1': 0.021024226444861394}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.3491618633270264\n",
      "epoch  1000 / 10000 ...    loss: 2.1292877197265625\n",
      "epoch  2000 / 10000 ...    loss: 1.9098149538040161\n",
      "epoch  3000 / 10000 ...    loss: 1.6905664205551147\n",
      "epoch  4000 / 10000 ...    loss: 1.4713331460952759\n",
      "epoch  5000 / 10000 ...    loss: 1.2521132230758667\n",
      "epoch  6000 / 10000 ...    loss: 1.0329272747039795\n",
      "epoch  7000 / 10000 ...    loss: 0.8138272762298584\n",
      "epoch  8000 / 10000 ...    loss: 0.5951207280158997\n",
      "epoch  9000 / 10000 ...    loss: 0.37858399748802185\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 10:27:28,842]\u001b[0m Trial 32 finished with value: 411996.625 and parameters: {'learning rate': 2.4334929689993092e-05, 'mask initialisation value': 0.23057038445144076, 'lambda1': 0.20956401960440574}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.539608359336853\n",
      "epoch  1000 / 10000 ...    loss: 0.5187942981719971\n",
      "epoch  2000 / 10000 ...    loss: 0.49821192026138306\n",
      "epoch  3000 / 10000 ...    loss: 0.47783195972442627\n",
      "epoch  4000 / 10000 ...    loss: 0.4576411843299866\n",
      "epoch  5000 / 10000 ...    loss: 0.437624990940094\n",
      "epoch  6000 / 10000 ...    loss: 0.4177696406841278\n",
      "epoch  7000 / 10000 ...    loss: 0.39807066321372986\n",
      "epoch  8000 / 10000 ...    loss: 0.3785427212715149\n",
      "epoch  9000 / 10000 ...    loss: 0.3592313528060913\n",
      "\u001b[32m[I 2021-08-06 11:08:02,385]\u001b[0m Trial 33 finished with value: 0.3402195870876312 and parameters: {'learning rate': 5.287842496021784e-06, 'mask initialisation value': 0.07127863517930075, 'lambda1': 0.09110577931524334}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.23990581929683685\n",
      "epoch  1000 / 10000 ...    loss: 0.23247233033180237\n",
      "epoch  2000 / 10000 ...    loss: 0.22512656450271606\n",
      "epoch  3000 / 10000 ...    loss: 0.21789680421352386\n",
      "epoch  4000 / 10000 ...    loss: 0.2107577621936798\n",
      "epoch  5000 / 10000 ...    loss: 0.2036190927028656\n",
      "epoch  6000 / 10000 ...    loss: 0.1965818852186203\n",
      "epoch  7000 / 10000 ...    loss: 0.18971674144268036\n",
      "epoch  8000 / 10000 ...    loss: 0.18295668065547943\n",
      "epoch  9000 / 10000 ...    loss: 0.17632727324962616\n",
      "\u001b[32m[I 2021-08-06 11:48:38,864]\u001b[0m Trial 34 finished with value: 0.169842928647995 and parameters: {'learning rate': 1.1268482112474659e-05, 'mask initialisation value': 0.13310249186381162, 'lambda1': 0.00032458045897542937}. Best is trial 26 with value: 0.06688917428255081.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.24502772092819214\n",
      "epoch  1000 / 10000 ...    loss: 0.10721584409475327\n",
      "epoch  2000 / 10000 ...    loss: 0.06491299718618393\n",
      "epoch  3000 / 10000 ...    loss: 0.052560728043317795\n",
      "epoch  4000 / 10000 ...    loss: 0.048085764050483704\n",
      "epoch  5000 / 10000 ...    loss: 10000257024.0\n",
      "epoch  6000 / 10000 ...    loss: 0.04614464193582535\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:13:00,604]\u001b[0m Trial 35 finished with value: 0.046144433319568634 and parameters: {'learning rate': 0.00031209356150052294, 'mask initialisation value': 0.12523017474875942, 'lambda1': 0.0009305844721048725}. Best is trial 35 with value: 0.046144433319568634.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.7714914679527283\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:14:58,390]\u001b[0m Trial 36 finished with value: 5055.6611328125 and parameters: {'learning rate': 0.0002818043503308399, 'mask initialisation value': 0.12050161935087078, 'lambda1': 0.0996501650371492}. Best is trial 35 with value: 0.046144433319568634.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.5078959465026855\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:15:31,765]\u001b[0m Trial 37 finished with value: 0.3330364227294922 and parameters: {'learning rate': 0.0011353805242146485, 'mask initialisation value': 0.13486524675581735, 'lambda1': 0.21321482324519336}. Best is trial 35 with value: 0.046144433319568634.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.2770671844482422\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:16:34,336]\u001b[0m Trial 38 finished with value: 0.10641993582248688 and parameters: {'learning rate': 0.01223759383510435, 'mask initialisation value': 0.8200613415912656, 'lambda1': 0.006148235176801229}. Best is trial 35 with value: 0.046144433319568634.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.6587045192718506\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:16:58,399]\u001b[0m Trial 39 finished with value: 0.6423734426498413 and parameters: {'learning rate': 0.011772394941451781, 'mask initialisation value': 0.7877600587548256, 'lambda1': 0.10329565090321637}. Best is trial 35 with value: 0.046144433319568634.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 12.976584434509277\n",
      "epoch  1000 / 10000 ...    loss: 6.812162399291992\n",
      "epoch  2000 / 10000 ...    loss: 0.6265041828155518\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:25:21,148]\u001b[0m Trial 40 finished with value: 43223948.0 and parameters: {'learning rate': 0.00044875040472805867, 'mask initialisation value': 0.9240720404214832, 'lambda1': 0.3173137515575416}. Best is trial 35 with value: 0.046144433319568634.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.09826557338237762\n",
      "epoch  1000 / 10000 ...    loss: 0.038954250514507294\n",
      "epoch  2000 / 10000 ...    loss: 0.026041477918624878\n",
      "epoch  3000 / 10000 ...    loss: 0.02012047730386257\n",
      "epoch  4000 / 10000 ...    loss: 0.016654670238494873\n",
      "epoch  5000 / 10000 ...    loss: 0.014611374586820602\n",
      "epoch  6000 / 10000 ...    loss: 0.01352858729660511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 12:51:55,225]\u001b[0m Trial 41 finished with value: 0.013330808840692043 and parameters: {'learning rate': 0.0001340071816148049, 'mask initialisation value': 0.7376908331394714, 'lambda1': 0.0006019786927240565}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.1619383841753006\n",
      "epoch  1000 / 10000 ...    loss: 0.10179698467254639\n",
      "epoch  2000 / 10000 ...    loss: 0.08370837569236755\n",
      "epoch  3000 / 10000 ...    loss: 0.07298796623945236\n",
      "epoch  4000 / 10000 ...    loss: 10000239616.0\n",
      "epoch  5000 / 10000 ...    loss: 0.05813314765691757\n",
      "epoch  6000 / 10000 ...    loss: 0.053009938448667526\n",
      "epoch  7000 / 10000 ...    loss: 0.049911029636859894\n",
      "epoch  8000 / 10000 ...    loss: 0.04832515865564346\n",
      "epoch  9000 / 10000 ...    loss: 0.04757468402385712\n",
      "\u001b[32m[I 2021-08-06 13:32:17,149]\u001b[0m Trial 42 finished with value: 0.0473172701895237 and parameters: {'learning rate': 0.00011673276857923825, 'mask initialisation value': 0.7445127179687636, 'lambda1': 0.002592940874563616}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.431349992752075\n",
      "epoch  1000 / 10000 ...    loss: 1.894806981086731\n",
      "epoch  2000 / 10000 ...    loss: 1.3831063508987427\n",
      "epoch  3000 / 10000 ...    loss: 0.8883681893348694\n",
      "epoch  4000 / 10000 ...    loss: 0.47071534395217896\n",
      "epoch  5000 / 10000 ...    loss: 0.37927132844924927\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 13:56:34,259]\u001b[0m Trial 43 finished with value: 1195.7113037109375 and parameters: {'learning rate': 0.00020147379099566865, 'mask initialisation value': 0.8421627034353228, 'lambda1': 0.06406844393005903}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.3321950435638428\n",
      "epoch  1000 / 10000 ...    loss: 2.180253028869629\n",
      "epoch  2000 / 10000 ...    loss: 2.033761501312256\n",
      "epoch  3000 / 10000 ...    loss: 1.8911851644515991\n",
      "epoch  4000 / 10000 ...    loss: 1.7509684562683105\n",
      "epoch  5000 / 10000 ...    loss: 1.6119298934936523\n",
      "epoch  6000 / 10000 ...    loss: 1.4735164642333984\n",
      "epoch  7000 / 10000 ...    loss: 1.335770845413208\n",
      "epoch  8000 / 10000 ...    loss: 1.1987322568893433\n",
      "epoch  9000 / 10000 ...    loss: 1.0625325441360474\n",
      "\u001b[32m[I 2021-08-06 14:37:02,752]\u001b[0m Trial 44 finished with value: 0.9278958439826965 and parameters: {'learning rate': 4.638061248135431e-05, 'mask initialisation value': 0.6823920834722033, 'lambda1': 0.07422421465891861}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 6.3549885749816895\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 14:37:32,305]\u001b[0m Trial 45 finished with value: 45262500.0 and parameters: {'learning rate': 0.007429228274898758, 'mask initialisation value': 0.7430073756125272, 'lambda1': 0.19125958166369425}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 4.718596458435059\n",
      "epoch  1000 / 10000 ...    loss: 4.18003511428833\n",
      "epoch  2000 / 10000 ...    loss: 3.6485438346862793\n",
      "epoch  3000 / 10000 ...    loss: 3.1181864738464355\n",
      "epoch  4000 / 10000 ...    loss: 2.588223457336426\n",
      "epoch  5000 / 10000 ...    loss: 2.05964732170105\n",
      "epoch  6000 / 10000 ...    loss: 1.5347795486450195\n",
      "epoch  7000 / 10000 ...    loss: 1.0213425159454346\n",
      "epoch  8000 / 10000 ...    loss: 0.5711649656295776\n",
      "epoch  9000 / 10000 ...    loss: 0.4383017420768738\n",
      "\u001b[32m[I 2021-08-06 15:18:00,804]\u001b[0m Trial 46 finished with value: 0.4277649521827698 and parameters: {'learning rate': 0.00010380639098970254, 'mask initialisation value': 0.8658468992129507, 'lambda1': 0.12229729046930868}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.9667856693267822\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 15:18:09,559]\u001b[0m Trial 47 finished with value: 1.1248667240142822 and parameters: {'learning rate': 0.08295064036276806, 'mask initialisation value': 0.6953807635581574, 'lambda1': 0.06106494277540193}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 28.47881507873535\n",
      "epoch  1000 / 10000 ...    loss: 15.820333480834961\n",
      "epoch  2000 / 10000 ...    loss: 3.141118049621582\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 15:27:13,859]\u001b[0m Trial 48 finished with value: 0.4619513154029846 and parameters: {'learning rate': 0.0004063885571148712, 'mask initialisation value': 0.9051952315406496, 'lambda1': 0.711447628532178}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 7.156807899475098\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 15:28:35,609]\u001b[0m Trial 49 finished with value: 0.478130578994751 and parameters: {'learning rate': 0.002037361015466142, 'mask initialisation value': 0.6441822123446747, 'lambda1': 0.24777524015631752}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.17640267312526703\n",
      "epoch  1000 / 10000 ...    loss: 0.14001713693141937\n",
      "epoch  2000 / 10000 ...    loss: 0.11242301017045975\n",
      "epoch  3000 / 10000 ...    loss: 0.08836232125759125\n",
      "epoch  4000 / 10000 ...    loss: 0.07190028578042984\n",
      "epoch  5000 / 10000 ...    loss: 0.06810291856527328\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 15:52:12,832]\u001b[0m Trial 50 finished with value: 0.06777244061231613 and parameters: {'learning rate': 0.0002441412269805612, 'mask initialisation value': 0.9698683147576529, 'lambda1': 0.0039050073919878496}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.3487258851528168\n",
      "epoch  1000 / 10000 ...    loss: 0.18947361409664154\n",
      "epoch  2000 / 10000 ...    loss: 1876575.5\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 16:01:49,983]\u001b[0m Trial 51 finished with value: 0.16978952288627625 and parameters: {'learning rate': 0.0006234874466852796, 'mask initialisation value': 0.9864040310896991, 'lambda1': 0.007909152457118537}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.149980068206787\n",
      "epoch  1000 / 10000 ...    loss: 1.6245944499969482\n",
      "epoch  2000 / 10000 ...    loss: 1.1332415342330933\n",
      "epoch  3000 / 10000 ...    loss: 0.6672561168670654\n",
      "epoch  4000 / 10000 ...    loss: 110049.9375\n",
      "epoch  5000 / 10000 ...    loss: 0.31993332505226135\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 16:24:27,693]\u001b[0m Trial 52 finished with value: 0.3176890015602112 and parameters: {'learning rate': 0.00021179378839426244, 'mask initialisation value': 0.7934927478099627, 'lambda1': 0.059557705291337915}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.06932651996612549\n",
      "epoch  1000 / 10000 ...    loss: 0.062472376972436905\n",
      "epoch  2000 / 10000 ...    loss: 0.05823514237999916\n",
      "epoch  3000 / 10000 ...    loss: 0.05400222912430763\n",
      "epoch  4000 / 10000 ...    loss: 0.04986356943845749\n",
      "epoch  5000 / 10000 ...    loss: 0.04590333625674248\n",
      "epoch  6000 / 10000 ...    loss: 0.04218759760260582\n",
      "epoch  7000 / 10000 ...    loss: 10000037888.0\n",
      "epoch  8000 / 10000 ...    loss: 0.03582370653748512\n",
      "epoch  9000 / 10000 ...    loss: 0.03340684622526169\n",
      "\u001b[32m[I 2021-08-06 17:04:58,941]\u001b[0m Trial 53 finished with value: 0.03177063167095184 and parameters: {'learning rate': 9.704526356378491e-05, 'mask initialisation value': 0.9900321524419549, 'lambda1': 0.0015169106768706526}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.9791299104690552\n",
      "epoch  1000 / 10000 ...    loss: 1.7408500909805298\n",
      "epoch  2000 / 10000 ...    loss: 1.5054396390914917\n",
      "epoch  3000 / 10000 ...    loss: 1.2724486589431763\n",
      "epoch  4000 / 10000 ...    loss: 1.043924331665039\n",
      "epoch  5000 / 10000 ...    loss: 0.8236289024353027\n",
      "epoch  6000 / 10000 ...    loss: 0.6207975149154663\n",
      "epoch  7000 / 10000 ...    loss: 0.45872196555137634\n",
      "epoch  8000 / 10000 ...    loss: 0.3848937153816223\n",
      "epoch  9000 / 10000 ...    loss: 0.3780890107154846\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 17:44:08,159]\u001b[0m Trial 54 finished with value: 0.3775142729282379 and parameters: {'learning rate': 0.00012926545353057238, 'mask initialisation value': 0.9786026437864946, 'lambda1': 0.045630853312866565}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.3949012756347656\n",
      "epoch  1000 / 10000 ...    loss: 3.025547504425049\n",
      "epoch  2000 / 10000 ...    loss: 2.660884380340576\n",
      "epoch  3000 / 10000 ...    loss: 2.2985687255859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4000 / 10000 ...    loss: 1.9376871585845947\n",
      "epoch  5000 / 10000 ...    loss: 1.5770039558410645\n",
      "epoch  6000 / 10000 ...    loss: 1.2172977924346924\n",
      "epoch  7000 / 10000 ...    loss: 0.8610847592353821\n",
      "epoch  8000 / 10000 ...    loss: 0.5231212377548218\n",
      "epoch  9000 / 10000 ...    loss: 41207.86328125\n",
      "\u001b[32m[I 2021-08-06 18:24:37,849]\u001b[0m Trial 55 finished with value: 0.31099987030029297 and parameters: {'learning rate': 6.608004121932565e-05, 'mask initialisation value': 0.5662980619434456, 'lambda1': 0.13060357387721727}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.1381924152374268\n",
      "epoch  1000 / 10000 ...    loss: 2.0586416721343994\n",
      "epoch  2000 / 10000 ...    loss: 1.9856493473052979\n",
      "epoch  3000 / 10000 ...    loss: 1.9145092964172363\n",
      "epoch  4000 / 10000 ...    loss: 1.8436055183410645\n",
      "epoch  5000 / 10000 ...    loss: 1.7727752923965454\n",
      "epoch  6000 / 10000 ...    loss: 1.7020177841186523\n",
      "epoch  7000 / 10000 ...    loss: 1.6313520669937134\n",
      "epoch  8000 / 10000 ...    loss: 1.560811996459961\n",
      "epoch  9000 / 10000 ...    loss: 1.4904425144195557\n",
      "\u001b[32m[I 2021-08-06 19:05:02,002]\u001b[0m Trial 56 finished with value: 1.420405626296997 and parameters: {'learning rate': 3.300392883317519e-05, 'mask initialisation value': 0.8954295184190688, 'lambda1': 0.05325053910678473}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 6.972886562347412\n",
      "epoch  1000 / 10000 ...    loss: 2.1501870155334473\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 19:10:43,361]\u001b[0m Trial 57 finished with value: 1427501.125 and parameters: {'learning rate': 0.0006883816737629343, 'mask initialisation value': 0.9493702652931597, 'lambda1': 0.16589160180605975}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.17801207304000854\n",
      "epoch  1000 / 10000 ...    loss: 0.09758219867944717\n",
      "epoch  2000 / 10000 ...    loss: 10000028672.0\n",
      "epoch  3000 / 10000 ...    loss: 0.06299570947885513\n",
      "epoch  4000 / 10000 ...    loss: 950394.1875\n",
      "epoch  5000 / 10000 ...    loss: 0.05686478316783905\n",
      "epoch  6000 / 10000 ...    loss: 0.0565110482275486\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 19:37:13,403]\u001b[0m Trial 58 finished with value: 0.0564342699944973 and parameters: {'learning rate': 0.0002640484699773918, 'mask initialisation value': 0.7653406584194782, 'lambda1': 0.0031786759666780676}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.1649680137634277\n",
      "epoch  1000 / 10000 ...    loss: 2.768554210662842\n",
      "epoch  2000 / 10000 ...    loss: 2.3855559825897217\n",
      "epoch  3000 / 10000 ...    loss: 2.0060462951660156\n",
      "epoch  4000 / 10000 ...    loss: 1.6282963752746582\n",
      "epoch  5000 / 10000 ...    loss: 1.2531592845916748\n",
      "epoch  6000 / 10000 ...    loss: 0.8840600252151489\n",
      "epoch  7000 / 10000 ...    loss: 0.5388527512550354\n",
      "epoch  8000 / 10000 ...    loss: 0.3515888452529907\n",
      "epoch  9000 / 10000 ...    loss: 0.3142857849597931\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 20:15:32,497]\u001b[0m Trial 59 finished with value: 0.3009481430053711 and parameters: {'learning rate': 9.851688744782857e-05, 'mask initialisation value': 0.7422608091978139, 'lambda1': 0.09416146830281903}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.2713232040405273\n",
      "epoch  1000 / 10000 ...    loss: 0.7283015251159668\n",
      "epoch  2000 / 10000 ...    loss: 0.3495897352695465\n",
      "epoch  3000 / 10000 ...    loss: 0.2917500138282776\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 20:29:51,313]\u001b[0m Trial 60 finished with value: 0.2823924720287323 and parameters: {'learning rate': 0.00031875283175098937, 'mask initialisation value': 0.6259173009834232, 'lambda1': 0.04197145907884874}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.22341546416282654\n",
      "epoch  1000 / 10000 ...    loss: 0.1365419179201126\n",
      "epoch  2000 / 10000 ...    loss: 10000103424.0\n",
      "epoch  3000 / 10000 ...    loss: 0.08719389885663986\n",
      "epoch  4000 / 10000 ...    loss: 0.07806897908449173\n",
      "epoch  5000 / 10000 ...    loss: 1516924.375\n",
      "epoch  6000 / 10000 ...    loss: 0.07473054528236389\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 20:56:02,805]\u001b[0m Trial 61 finished with value: 0.07464625686407089 and parameters: {'learning rate': 0.00023237889840473279, 'mask initialisation value': 0.7547496191601241, 'lambda1': 0.004491672214467114}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.1522698402404785\n",
      "epoch  1000 / 10000 ...    loss: 1.038038730621338\n",
      "epoch  2000 / 10000 ...    loss: 0.930406391620636\n",
      "epoch  3000 / 10000 ...    loss: 0.8293226957321167\n",
      "epoch  4000 / 10000 ...    loss: 0.7337309718132019\n",
      "epoch  5000 / 10000 ...    loss: 0.6428401470184326\n",
      "epoch  6000 / 10000 ...    loss: 0.5563400387763977\n",
      "epoch  7000 / 10000 ...    loss: 0.4750381112098694\n",
      "epoch  8000 / 10000 ...    loss: 0.4025628864765167\n",
      "epoch  9000 / 10000 ...    loss: 0.34737515449523926\n",
      "\u001b[32m[I 2021-08-06 21:36:29,598]\u001b[0m Trial 62 finished with value: 0.32047298550605774 and parameters: {'learning rate': 5.1453246793465516e-05, 'mask initialisation value': 0.4729321621955305, 'lambda1': 0.0478302318814524}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.8193819522857666\n",
      "epoch  1000 / 10000 ...    loss: 3.135592460632324\n",
      "epoch  2000 / 10000 ...    loss: 2.463855266571045\n",
      "epoch  3000 / 10000 ...    loss: 1.795619010925293\n",
      "epoch  4000 / 10000 ...    loss: 1.1309787034988403\n",
      "epoch  5000 / 10000 ...    loss: 0.5011246204376221\n",
      "epoch  6000 / 10000 ...    loss: 0.3078916072845459\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 22:01:02,191]\u001b[0m Trial 63 finished with value: 0.32118692994117737 and parameters: {'learning rate': 0.0001324773621266237, 'mask initialisation value': 0.6940864608202911, 'lambda1': 0.12158554376130955}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.32427656650543213\n",
      "epoch  1000 / 10000 ...    loss: 0.28083667159080505\n",
      "epoch  2000 / 10000 ...    loss: 0.2604445219039917\n",
      "epoch  3000 / 10000 ...    loss: 0.2422451376914978\n",
      "epoch  4000 / 10000 ...    loss: 0.22452384233474731\n",
      "epoch  5000 / 10000 ...    loss: 0.20702913403511047\n",
      "epoch  6000 / 10000 ...    loss: 0.18990378081798553\n",
      "epoch  7000 / 10000 ...    loss: 0.17337629199028015\n",
      "epoch  8000 / 10000 ...    loss: 0.15773935616016388\n",
      "epoch  9000 / 10000 ...    loss: 0.14332319796085358\n",
      "\u001b[32m[I 2021-08-06 22:41:27,106]\u001b[0m Trial 64 finished with value: 0.1305854320526123 and parameters: {'learning rate': 7.39541794510213e-05, 'mask initialisation value': 0.8742377622549736, 'lambda1': 0.007409182328111886}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 21.58055877685547\n",
      "epoch  1000 / 10000 ...    loss: 10.021724700927734\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 22:48:57,877]\u001b[0m Trial 65 finished with value: 0.4190305769443512 and parameters: {'learning rate': 0.0003010106458455179, 'mask initialisation value': 0.5549357677217477, 'lambda1': 0.8749542862231848}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.5270473957061768\n",
      "epoch  1000 / 10000 ...    loss: 0.522955060005188\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 22:53:47,039]\u001b[0m Trial 66 finished with value: 0.4989987015724182 and parameters: {'learning rate': 0.0009424160230946378, 'mask initialisation value': 0.9400104573092445, 'lambda1': 0.0844969977548446}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.3403217792510986\n",
      "epoch  1000 / 10000 ...    loss: 1.13174569606781\n",
      "epoch  2000 / 10000 ...    loss: 0.9261553287506104\n",
      "epoch  3000 / 10000 ...    loss: 0.726579487323761\n",
      "epoch  4000 / 10000 ...    loss: 0.5402429103851318\n",
      "epoch  5000 / 10000 ...    loss: 0.3851757347583771\n",
      "epoch  6000 / 10000 ...    loss: 994491.0\n",
      "epoch  7000 / 10000 ...    loss: 0.3000568747520447\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-06 23:22:48,791]\u001b[0m Trial 67 finished with value: 0.2999632954597473 and parameters: {'learning rate': 0.00017363965819202094, 'mask initialisation value': 0.9889574814318384, 'lambda1': 0.030602992117401195}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.15192709863185883\n",
      "epoch  1000 / 10000 ...    loss: 0.1335979849100113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2000 / 10000 ...    loss: 0.11922052502632141\n",
      "epoch  3000 / 10000 ...    loss: 0.10839847475290298\n",
      "epoch  4000 / 10000 ...    loss: 0.10056113451719284\n",
      "epoch  5000 / 10000 ...    loss: 0.09473554790019989\n",
      "epoch  6000 / 10000 ...    loss: 0.09010299295186996\n",
      "epoch  7000 / 10000 ...    loss: 0.08613680303096771\n",
      "epoch  8000 / 10000 ...    loss: 0.08266504853963852\n",
      "epoch  9000 / 10000 ...    loss: 0.07961220294237137\n",
      "\u001b[32m[I 2021-08-07 00:03:09,485]\u001b[0m Trial 68 finished with value: 0.07690092921257019 and parameters: {'learning rate': 2.31697688658579e-05, 'mask initialisation value': 0.7682201037081002, 'lambda1': 0.002423126837584391}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.5770201683044434\n",
      "epoch  1000 / 10000 ...    loss: 0.31848812103271484\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 00:08:02,235]\u001b[0m Trial 69 finished with value: 0.27524083852767944 and parameters: {'learning rate': 3.622631790249389e-05, 'mask initialisation value': 0.04288138569110531, 'lambda1': 0.16765740017016037}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 20.923959732055664\n",
      "epoch  1000 / 10000 ...    loss: 18.225475311279297\n",
      "epoch  2000 / 10000 ...    loss: 15.525635719299316\n",
      "epoch  3000 / 10000 ...    loss: 12.824514389038086\n",
      "epoch  4000 / 10000 ...    loss: 10.12153148651123\n",
      "epoch  5000 / 10000 ...    loss: 7.417374610900879\n",
      "epoch  6000 / 10000 ...    loss: 4.712277889251709\n",
      "epoch  7000 / 10000 ...    loss: 2.0074245929718018\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 00:40:25,319]\u001b[0m Trial 70 finished with value: 0.31432104110717773 and parameters: {'learning rate': 0.00011073459831472916, 'mask initialisation value': 0.8465365338322587, 'lambda1': 0.5582618979026471}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.0712823867797852\n",
      "epoch  1000 / 10000 ...    loss: 0.7920653820037842\n",
      "epoch  2000 / 10000 ...    loss: 0.5643046498298645\n",
      "epoch  3000 / 10000 ...    loss: 0.36734092235565186\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 00:56:25,408]\u001b[0m Trial 71 finished with value: 1425316.75 and parameters: {'learning rate': 0.00021256634643302576, 'mask initialisation value': 0.7387795377872374, 'lambda1': 0.030424001752530305}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.49432635307312\n",
      "epoch  1000 / 10000 ...    loss: 0.855355978012085\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 01:03:00,315]\u001b[0m Trial 72 finished with value: 0.3154332935810089 and parameters: {'learning rate': 0.0005310471875730873, 'mask initialisation value': 0.70575593981006, 'lambda1': 0.0771833770046047}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.20533394813537598\n",
      "epoch  1000 / 10000 ...    loss: 0.10436274856328964\n",
      "epoch  2000 / 10000 ...    loss: 0.07884670794010162\n",
      "epoch  3000 / 10000 ...    loss: 0.06702837347984314\n",
      "epoch  4000 / 10000 ...    loss: 0.06350429356098175\n",
      "epoch  5000 / 10000 ...    loss: 0.06245531514286995\n",
      "epoch  6000 / 10000 ...    loss: 0.06215263903141022\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 01:28:30,798]\u001b[0m Trial 73 finished with value: 0.062119010835886 and parameters: {'learning rate': 0.0002551662429815214, 'mask initialisation value': 0.660277208317977, 'lambda1': 0.0035776177781834386}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.1489418745040894\n",
      "epoch  1000 / 10000 ...    loss: 0.6951687335968018\n",
      "epoch  2000 / 10000 ...    loss: 0.3605803847312927\n",
      "epoch  3000 / 10000 ...    loss: 0.2819986045360565\n",
      "epoch  4000 / 10000 ...    loss: 0.27757179737091064\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 01:46:57,247]\u001b[0m Trial 74 finished with value: 0.27618229389190674 and parameters: {'learning rate': 0.0003149293354522957, 'mask initialisation value': 0.6745516476175866, 'lambda1': 0.03530454901034611}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.6020724773406982\n",
      "epoch  1000 / 10000 ...    loss: 3.269477605819702\n",
      "epoch  2000 / 10000 ...    loss: 2.941905975341797\n",
      "epoch  3000 / 10000 ...    loss: 2.6164584159851074\n",
      "epoch  4000 / 10000 ...    loss: 2.292309284210205\n",
      "epoch  5000 / 10000 ...    loss: 1.968681812286377\n",
      "epoch  6000 / 10000 ...    loss: 1.6453665494918823\n",
      "epoch  7000 / 10000 ...    loss: 1.3226923942565918\n",
      "epoch  8000 / 10000 ...    loss: 1.002736210823059\n",
      "epoch  9000 / 10000 ...    loss: 0.6907159090042114\n",
      "\u001b[32m[I 2021-08-07 02:31:32,483]\u001b[0m Trial 75 finished with value: 0.42436838150024414 and parameters: {'learning rate': 6.261428291121051e-05, 'mask initialisation value': 0.6379738292845034, 'lambda1': 0.12399786207951305}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.24744240939617157\n",
      "epoch  1000 / 10000 ...    loss: 0.18495261669158936\n",
      "epoch  2000 / 10000 ...    loss: 0.14469176530838013\n",
      "epoch  3000 / 10000 ...    loss: 0.12089613825082779\n",
      "epoch  4000 / 10000 ...    loss: 0.10524038970470428\n",
      "epoch  5000 / 10000 ...    loss: 0.0938105583190918\n",
      "epoch  6000 / 10000 ...    loss: 0.08584649860858917\n",
      "epoch  7000 / 10000 ...    loss: 0.08110248297452927\n",
      "epoch  8000 / 10000 ...    loss: 0.07843662053346634\n",
      "epoch  9000 / 10000 ...    loss: 0.07717601209878922\n",
      "\u001b[32m[I 2021-08-07 03:11:59,725]\u001b[0m Trial 76 finished with value: 0.07655844837427139 and parameters: {'learning rate': 8.271164390831815e-05, 'mask initialisation value': 0.5034269091657269, 'lambda1': 0.004616009897154966}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.14952418208122253\n",
      "epoch  1000 / 10000 ...    loss: 0.03884854167699814\n",
      "epoch  2000 / 10000 ...    loss: 0.026289425790309906\n",
      "epoch  3000 / 10000 ...    loss: 0.023060515522956848\n",
      "epoch  4000 / 10000 ...    loss: 0.022076431661844254\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 03:29:19,109]\u001b[0m Trial 77 finished with value: 0.021955953910946846 and parameters: {'learning rate': 0.00038985405127466076, 'mask initialisation value': 0.5895624582701937, 'lambda1': 0.0010931747763711394}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 11.858773231506348\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 03:31:04,101]\u001b[0m Trial 78 finished with value: 0.5268585681915283 and parameters: {'learning rate': 0.0014062685438156165, 'mask initialisation value': 0.5846471093847901, 'lambda1': 0.45440158615914944}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.3714044094085693\n",
      "epoch  1000 / 10000 ...    loss: 1.0500409603118896\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 03:38:51,769]\u001b[0m Trial 79 finished with value: 5615.87158203125 and parameters: {'learning rate': 0.000388624092494971, 'mask initialisation value': 0.6112839387770481, 'lambda1': 0.08355920095503815}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 3.5538623332977295\n",
      "epoch  1000 / 10000 ...    loss: 2.9525763988494873\n",
      "epoch  2000 / 10000 ...    loss: 2.3651018142700195\n",
      "epoch  3000 / 10000 ...    loss: 1.7812843322753906\n",
      "epoch  4000 / 10000 ...    loss: 1.2014826536178589\n",
      "epoch  5000 / 10000 ...    loss: 0.63991779088974\n",
      "epoch  6000 / 10000 ...    loss: 0.3341902494430542\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 04:05:42,486]\u001b[0m Trial 80 finished with value: 1.0177724361419678 and parameters: {'learning rate': 0.00012824520211887638, 'mask initialisation value': 0.7104343175871383, 'lambda1': 0.1104768444091917}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.0320910215377808\n",
      "epoch  1000 / 10000 ...    loss: 0.8414857983589172\n",
      "epoch  2000 / 10000 ...    loss: 0.6839745044708252\n",
      "epoch  3000 / 10000 ...    loss: 0.5334184169769287\n",
      "epoch  4000 / 10000 ...    loss: 0.3956790566444397\n",
      "epoch  5000 / 10000 ...    loss: 0.2914581298828125\n",
      "epoch  6000 / 10000 ...    loss: 58615.8828125\n",
      "epoch  7000 / 10000 ...    loss: 0.2575198709964752\n",
      "epoch  8000 / 10000 ...    loss: 0.2571796774864197\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 04:39:34,976]\u001b[0m Trial 81 finished with value: 0.2571318745613098 and parameters: {'learning rate': 0.00015753717910006295, 'mask initialisation value': 0.808520118538393, 'lambda1': 0.027278157685274668}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.6679999828338623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 04:43:11,447]\u001b[0m Trial 82 finished with value: 0.3171689212322235 and parameters: {'learning rate': 0.0008057426383822984, 'mask initialisation value': 0.533372671475315, 'lambda1': 0.06499065385734365}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.2253299355506897\n",
      "epoch  1000 / 10000 ...    loss: 0.12175914645195007\n",
      "epoch  2000 / 10000 ...    loss: 0.09254312515258789\n",
      "epoch  3000 / 10000 ...    loss: 0.07750531286001205\n",
      "epoch  4000 / 10000 ...    loss: 0.07282456755638123\n",
      "epoch  5000 / 10000 ...    loss: 0.07143566757440567\n",
      "epoch  6000 / 10000 ...    loss: 0.07106206566095352\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 05:08:22,138]\u001b[0m Trial 83 finished with value: 0.0710296556353569 and parameters: {'learning rate': 0.00023550359749440375, 'mask initialisation value': 0.6477692162574176, 'lambda1': 0.004220667801148104}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.9625586271286011\n",
      "epoch  1000 / 10000 ...    loss: 0.4048958718776703\n",
      "epoch  2000 / 10000 ...    loss: 0.2550984025001526\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 05:16:38,744]\u001b[0m Trial 84 finished with value: 0.2642378509044647 and parameters: {'learning rate': 0.0005483316790612061, 'mask initialisation value': 0.7228042974355441, 'lambda1': 0.02754612295115179}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.8094313144683838\n",
      "epoch  1000 / 10000 ...    loss: 0.8827621340751648\n",
      "epoch  2000 / 10000 ...    loss: 1138192.125\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 05:26:16,369]\u001b[0m Trial 85 finished with value: 0.295896977186203 and parameters: {'learning rate': 0.0003980425570848957, 'mask initialisation value': 0.6642083864442428, 'lambda1': 0.05826255358923528}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.111342668533325\n",
      "epoch  1000 / 10000 ...    loss: 1.7896606922149658\n",
      "epoch  2000 / 10000 ...    loss: 1.484643578529358\n",
      "epoch  3000 / 10000 ...    loss: 1.1881364583969116\n",
      "epoch  4000 / 10000 ...    loss: 0.8984260559082031\n",
      "epoch  5000 / 10000 ...    loss: 0.6211849451065063\n",
      "epoch  6000 / 10000 ...    loss: 0.3997794985771179\n",
      "epoch  7000 / 10000 ...    loss: 44245.11328125\n",
      "epoch  8000 / 10000 ...    loss: 0.3061918020248413\n",
      "epoch  9000 / 10000 ...    loss: 0.2868562340736389\n",
      "\u001b[32m[I 2021-08-07 06:06:44,647]\u001b[0m Trial 86 finished with value: 0.2778940498828888 and parameters: {'learning rate': 9.54714937751045e-05, 'mask initialisation value': 0.5759516059205139, 'lambda1': 0.07807260745225042}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.17491388320922852\n",
      "epoch  1000 / 10000 ...    loss: 0.10906992107629776\n",
      "epoch  2000 / 10000 ...    loss: 0.09067779779434204\n",
      "epoch  3000 / 10000 ...    loss: 0.07783373445272446\n",
      "epoch  4000 / 10000 ...    loss: 0.06766416132450104\n",
      "epoch  5000 / 10000 ...    loss: 0.060511697083711624\n",
      "epoch  6000 / 10000 ...    loss: 0.05720685422420502\n",
      "epoch  7000 / 10000 ...    loss: 0.05581196770071983\n",
      "epoch  8000 / 10000 ...    loss: 0.05541262775659561\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 06:42:09,819]\u001b[0m Trial 87 finished with value: 0.05530408024787903 and parameters: {'learning rate': 0.000157462205346452, 'mask initialisation value': 0.7700365693110237, 'lambda1': 0.003108853366482629}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 5.0279083251953125\n",
      "epoch  1000 / 10000 ...    loss: 4.704137325286865\n",
      "epoch  2000 / 10000 ...    loss: 4.383630752563477\n",
      "epoch  3000 / 10000 ...    loss: 4.064255237579346\n",
      "epoch  4000 / 10000 ...    loss: 3.745269775390625\n",
      "epoch  5000 / 10000 ...    loss: 3.4266552925109863\n",
      "epoch  6000 / 10000 ...    loss: 3.1079325675964355\n",
      "epoch  7000 / 10000 ...    loss: 2.7891290187835693\n",
      "epoch  8000 / 10000 ...    loss: 2.470257520675659\n",
      "epoch  9000 / 10000 ...    loss: 2.1515777111053467\n",
      "\u001b[32m[I 2021-08-07 07:22:39,115]\u001b[0m Trial 88 finished with value: 1.8332748413085938 and parameters: {'learning rate': 5.2208679869651115e-05, 'mask initialisation value': 0.7756633503026238, 'lambda1': 0.14476015846220158}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.3170124292373657\n",
      "epoch  1000 / 10000 ...    loss: 0.9996857643127441\n",
      "epoch  2000 / 10000 ...    loss: 0.7304665446281433\n",
      "epoch  3000 / 10000 ...    loss: 0.48774129152297974\n",
      "epoch  4000 / 10000 ...    loss: 0.32471346855163574\n",
      "epoch  5000 / 10000 ...    loss: 0.2949483096599579\n",
      "epoch  6000 / 10000 ...    loss: 0.28346776962280273\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 07:48:26,858]\u001b[0m Trial 89 finished with value: 0.27978527545928955 and parameters: {'learning rate': 0.00017574647851917, 'mask initialisation value': 0.6651179943282388, 'lambda1': 0.04143287568572126}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 24.27006721496582\n",
      "epoch  1000 / 10000 ...    loss: 20.53607177734375\n",
      "epoch  2000 / 10000 ...    loss: 16.799711227416992\n",
      "epoch  3000 / 10000 ...    loss: 13.06097412109375\n",
      "epoch  4000 / 10000 ...    loss: 9.320112228393555\n",
      "epoch  5000 / 10000 ...    loss: 5.578126907348633\n",
      "epoch  6000 / 10000 ...    loss: 1.836236596107483\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 08:14:29,148]\u001b[0m Trial 90 finished with value: 0.3315109610557556 and parameters: {'learning rate': 0.00013056101815709547, 'mask initialisation value': 0.8382596218591433, 'lambda1': 0.6540621179629413}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.6724793910980225\n",
      "epoch  1000 / 10000 ...    loss: 0.4331187307834625\n",
      "epoch  2000 / 10000 ...    loss: 0.28537702560424805\n",
      "epoch  3000 / 10000 ...    loss: 0.22318027913570404\n",
      "epoch  4000 / 10000 ...    loss: 0.21683040261268616\n",
      "epoch  5000 / 10000 ...    loss: 0.2164628952741623\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 08:35:28,062]\u001b[0m Trial 91 finished with value: 0.2164442539215088 and parameters: {'learning rate': 0.0002505558026748579, 'mask initialisation value': 0.6090868970474798, 'lambda1': 0.02069827263198039}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.2509608864784241\n",
      "epoch  1000 / 10000 ...    loss: 0.14392977952957153\n",
      "epoch  2000 / 10000 ...    loss: 0.10665502399206161\n",
      "epoch  3000 / 10000 ...    loss: 0.08936973661184311\n",
      "epoch  4000 / 10000 ...    loss: 0.08548115938901901\n",
      "epoch  5000 / 10000 ...    loss: 0.08479034900665283\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 08:58:16,057]\u001b[0m Trial 92 finished with value: 0.08469139039516449 and parameters: {'learning rate': 0.0002967908472053544, 'mask initialisation value': 0.7292141058087935, 'lambda1': 0.005272473740566429}. Best is trial 41 with value: 0.013330808840692043.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.06516149640083313\n",
      "epoch  1000 / 10000 ...    loss: 0.004650657996535301\n",
      "epoch  2000 / 10000 ...    loss: 0.0017298368038609624\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:07:12,594]\u001b[0m Trial 93 finished with value: 0.001627867459319532 and parameters: {'learning rate': 0.0003698456262469959, 'mask initialisation value': 0.790324348115668, 'lambda1': 5.7129601274279445e-05}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 1.6551616191864014\n",
      "epoch  1000 / 10000 ...    loss: 0.9947259426116943\n",
      "epoch  2000 / 10000 ...    loss: 0.43990206718444824\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:17:22,524]\u001b[0m Trial 94 finished with value: 1689175.875 and parameters: {'learning rate': 0.00036137860446527605, 'mask initialisation value': 0.7912382144953248, 'lambda1': 0.045552449677788626}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.08010280132293701\n",
      "epoch  1000 / 10000 ...    loss: 0.006299895700067282\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:24:03,968]\u001b[0m Trial 95 finished with value: 0.005218768958002329 and parameters: {'learning rate': 0.0007312301894615857, 'mask initialisation value': 0.7565621092049042, 'lambda1': 0.0002089515812710598}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 12.516550064086914\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:27:04,669]\u001b[0m Trial 96 finished with value: 0.48253849148750305 and parameters: {'learning rate': 0.0010506423664781654, 'mask initialisation value': 0.7661571321632625, 'lambda1': 0.3677259769736911}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 / 10000 ...    loss: 3.8155786991119385\n",
      "epoch  1000 / 10000 ...    loss: 0.785358190536499\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:32:26,807]\u001b[0m Trial 97 finished with value: 0.3923491835594177 and parameters: {'learning rate': 0.0007078967322027363, 'mask initialisation value': 0.8114900201268282, 'lambda1': 0.10484744863795542}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 2.013596296310425\n",
      "epoch  1000 / 10000 ...    loss: 0.8071187734603882\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:40:13,801]\u001b[0m Trial 98 finished with value: 0.3014964461326599 and parameters: {'learning rate': 0.0005054522844677527, 'mask initialisation value': 0.721822802086252, 'lambda1': 0.06053505956158341}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n",
      "epoch  0 / 10000 ...    loss: 0.7902801036834717\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-07 09:42:24,228]\u001b[0m Trial 99 finished with value: 0.23350375890731812 and parameters: {'learning rate': 0.0024907534917260137, 'mask initialisation value': 0.7514398729899154, 'lambda1': 0.02155826015482266}. Best is trial 93 with value: 0.001627867459319532.\u001b[0m\n",
      "Done\n",
      "all plots saved in /home/jupyter/profiles/tko/bachelor thesis/proloaf/./oracles/interpretation/opsd_GRU_gnll_opsd_fh24_onehot_ssr/plots/\n",
      "Elapsed time:  131221.78638282046\n",
      "Traceback (most recent call last):\n",
      "  File \"./source/fc_interpret.py\", line 472, in <module>\n",
      "    rmse_perturbated = criterion(targets, perturbated_prediction).detach().numpy()\n",
      "  File \"/home/jupyter/miniconda3/lib/python3.8/site-packages/utils/eval_metrics.py\", line 311, in rmse\n",
      "    raise ValueError('dimensions of predictions and targets need to be compatible')\n",
      "ValueError: dimensions of predictions and targets need to be compatible\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python3 ./source/fc_interpret.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opsd forecast horizon 24h no aux features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ./source/fc_interpret.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opsd forecast horizon 24h sinus aux features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python3 ./source/fc_interpret.py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perturbated prediction evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reserver",
   "language": "python",
   "name": "reserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
