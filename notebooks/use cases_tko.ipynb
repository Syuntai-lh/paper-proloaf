{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# opsd forecast horizon 24h one hot encoded aux features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mondays + days with highest/lowest load + days with highest/lowest temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "reading csv...\n",
      "done\n",
      "scaling data...\n",
      "done\n",
      "loading input data...\n",
      "Done\n",
      "timesteps 43673\n",
      "num_features1 1\n",
      "num_features2 45\n",
      "targets: 1\n",
      "history_horizon 128\n",
      "forecast_horizon 24\n",
      "load net...\n",
      "Done.\n",
      "\n",
      "\n",
      "timestep:  136\n",
      "create saliency maps...\n",
      "epoch  0 / 5000 ...    loss: 3.3160905838012695\n",
      "epoch  1000 / 5000 ...    loss: 3.221003770828247\n",
      "epoch  2000 / 5000 ...    loss: 3.129687547683716\n",
      "epoch  3000 / 5000 ...    loss: 3.038538694381714\n",
      "epoch  4000 / 5000 ...    loss: 2.947392463684082\n",
      "\u001b[32m[I 2021-08-09 18:39:32,226]\u001b[0m Trial 0 finished with value: 2.85634708404541 and parameters: {'learning rate': 2.832775784388863e-05, 'mask initialisation value': 0.9499964390185457, 'lambda1': 0.07860599779673662}. Best is trial 0 with value: 2.85634708404541.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.589141845703125\n",
      "epoch  1000 / 5000 ...    loss: 0.49169081449508667\n",
      "epoch  2000 / 5000 ...    loss: 0.41408342123031616\n",
      "epoch  3000 / 5000 ...    loss: 0.3519810736179352\n",
      "epoch  4000 / 5000 ...    loss: 0.3036514222621918\n",
      "\u001b[32m[I 2021-08-09 19:00:31,640]\u001b[0m Trial 1 finished with value: 0.2722121477127075 and parameters: {'learning rate': 7.623827530069345e-05, 'mask initialisation value': 0.382895732674123, 'lambda1': 0.024066344072770397}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.9031014442443848\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 19:01:17,225]\u001b[0m Trial 2 finished with value: 0.3872300386428833 and parameters: {'learning rate': 0.0029231808361605415, 'mask initialisation value': 0.4269125613450976, 'lambda1': 0.09187480112873743}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.3816285133361816\n",
      "epoch  1000 / 5000 ...    loss: 0.3329218626022339\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 19:06:51,978]\u001b[0m Trial 3 finished with value: 0.30276381969451904 and parameters: {'learning rate': 0.0007093587130440862, 'mask initialisation value': 0.6223642976720639, 'lambda1': 0.046004462639921084}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.37386777997016907\n",
      "epoch  1000 / 5000 ...    loss: 0.35141122341156006\n",
      "epoch  2000 / 5000 ...    loss: 0.331539511680603\n",
      "epoch  3000 / 5000 ...    loss: 0.3138135075569153\n",
      "epoch  4000 / 5000 ...    loss: 0.2978169322013855\n",
      "\u001b[32m[I 2021-08-09 19:27:49,902]\u001b[0m Trial 4 finished with value: 0.28337714076042175 and parameters: {'learning rate': 2.4045679547304743e-05, 'mask initialisation value': 0.5945551953042857, 'lambda1': 0.009490352552789584}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.451459139585495\n",
      "epoch  1000 / 5000 ...    loss: 0.4271421432495117\n",
      "epoch  2000 / 5000 ...    loss: 0.40416419506073\n",
      "epoch  3000 / 5000 ...    loss: 0.3824382424354553\n",
      "epoch  4000 / 5000 ...    loss: 0.36206871271133423\n",
      "\u001b[32m[I 2021-08-09 19:48:44,488]\u001b[0m Trial 5 finished with value: 0.3431861400604248 and parameters: {'learning rate': 1.4924471447182562e-05, 'mask initialisation value': 0.14697878559684074, 'lambda1': 0.03220852437919515}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6645461916923523\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 19:49:00,560]\u001b[0m Trial 6 finished with value: 0.3257911205291748 and parameters: {'learning rate': 0.0034692627209964738, 'mask initialisation value': 0.13487877278988725, 'lambda1': 0.07036218661759171}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 2.161343812942505\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 19:51:18,677]\u001b[0m Trial 7 finished with value: 525654.625 and parameters: {'learning rate': 0.0020920594523560513, 'mask initialisation value': 0.8684076870425734, 'lambda1': 0.055194655881487864}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.4113128185272217\n",
      "epoch  1000 / 5000 ...    loss: 1.3244789838790894\n",
      "epoch  2000 / 5000 ...    loss: 1.2402695417404175\n",
      "epoch  3000 / 5000 ...    loss: 1.1581016778945923\n",
      "epoch  4000 / 5000 ...    loss: 1.0774880647659302\n",
      "\u001b[32m[I 2021-08-09 20:12:04,559]\u001b[0m Trial 8 finished with value: 0.9980887174606323 and parameters: {'learning rate': 2.777730532681778e-05, 'mask initialisation value': 0.39458672459691346, 'lambda1': 0.07069571057497347}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 2.2656972408294678\n",
      "epoch  1000 / 5000 ...    loss: 2.2573602199554443\n",
      "epoch  2000 / 5000 ...    loss: 2.2490289211273193\n",
      "epoch  3000 / 5000 ...    loss: 2.2407140731811523\n",
      "epoch  4000 / 5000 ...    loss: 2.232402801513672\n",
      "\u001b[32m[I 2021-08-09 20:32:54,664]\u001b[0m Trial 9 finished with value: 2.224118232727051 and parameters: {'learning rate': 1.950816557562953e-06, 'mask initialisation value': 0.4864946678652974, 'lambda1': 0.09824110754172016}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.2769733965396881\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 20:33:18,005]\u001b[0m Trial 10 finished with value: 10203115520.0 and parameters: {'learning rate': 0.05940135090917473, 'mask initialisation value': 0.0036955120049556034, 'lambda1': 0.0012489168648178312}. Best is trial 1 with value: 0.2722121477127075.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.31172874569892883\n",
      "epoch  1000 / 5000 ...    loss: 0.23190419375896454\n",
      "epoch  2000 / 5000 ...    loss: 0.19437147676944733\n",
      "epoch  3000 / 5000 ...    loss: 0.16777125000953674\n",
      "epoch  4000 / 5000 ...    loss: 0.14683909714221954\n",
      "\u001b[32m[I 2021-08-09 20:54:12,740]\u001b[0m Trial 11 finished with value: 0.1312822550535202 and parameters: {'learning rate': 0.00012794713397839625, 'mask initialisation value': 0.7051032112417821, 'lambda1': 0.007017883287682885}. Best is trial 11 with value: 0.1312822550535202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6759144067764282\n",
      "epoch  1000 / 5000 ...    loss: 0.4836810529232025\n",
      "epoch  2000 / 5000 ...    loss: 0.3505312204360962\n",
      "epoch  3000 / 5000 ...    loss: 0.25347480177879333\n",
      "epoch  4000 / 5000 ...    loss: 0.2262827455997467\n",
      "\u001b[32m[I 2021-08-09 21:15:07,816]\u001b[0m Trial 12 finished with value: 0.22388403117656708 and parameters: {'learning rate': 0.0002486894542742118, 'mask initialisation value': 0.768282445349571, 'lambda1': 0.017717170493670567}. Best is trial 11 with value: 0.1312822550535202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6101274490356445\n",
      "epoch  1000 / 5000 ...    loss: 0.457412987947464\n",
      "epoch  2000 / 5000 ...    loss: 0.3536786735057831\n",
      "epoch  3000 / 5000 ...    loss: 0.26660895347595215\n",
      "epoch  4000 / 5000 ...    loss: 0.2174295336008072\n",
      "\u001b[32m[I 2021-08-09 21:36:02,117]\u001b[0m Trial 13 finished with value: 0.20758375525474548 and parameters: {'learning rate': 0.00021569478263844862, 'mask initialisation value': 0.7952078933303921, 'lambda1': 0.015474778540397827}. Best is trial 11 with value: 0.1312822550535202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.14402028918266296\n",
      "epoch  1000 / 5000 ...    loss: 0.06452719122171402\n",
      "epoch  2000 / 5000 ...    loss: 0.04968519136309624\n",
      "epoch  3000 / 5000 ...    loss: 0.0435791052877903\n",
      "epoch  4000 / 5000 ...    loss: 0.042249806225299835\n",
      "\u001b[32m[I 2021-08-09 21:56:55,447]\u001b[0m Trial 14 finished with value: 0.04183008521795273 and parameters: {'learning rate': 0.0002781142858103405, 'mask initialisation value': 0.7572656378328299, 'lambda1': 0.0019777493589624995}. Best is trial 14 with value: 0.04183008521795273.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.20356473326683044\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 21:57:35,042]\u001b[0m Trial 15 finished with value: 0.0858675017952919 and parameters: {'learning rate': 0.025149154376746606, 'mask initialisation value': 0.6850025924560699, 'lambda1': 0.0034571508990983634}. Best is trial 14 with value: 0.04183008521795273.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.4969044923782349\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 21:57:50,531]\u001b[0m Trial 16 finished with value: 114953688.0 and parameters: {'learning rate': 0.08892216225730266, 'mask initialisation value': 0.9446346755972392, 'lambda1': 0.035415621595432885}. Best is trial 14 with value: 0.04183008521795273.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.13299719989299774\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 21:58:27,509]\u001b[0m Trial 17 finished with value: 10058679296.0 and parameters: {'learning rate': 0.023008635595665853, 'mask initialisation value': 0.6086107096033934, 'lambda1': 0.00045903921877042545}. Best is trial 14 with value: 0.04183008521795273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 / 5000 ...    loss: 0.9078808426856995\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 21:58:56,492]\u001b[0m Trial 18 finished with value: 0.3241594433784485 and parameters: {'learning rate': 0.014134103557082524, 'mask initialisation value': 0.7012648634748508, 'lambda1': 0.02626361985145957}. Best is trial 14 with value: 0.04183008521795273.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.02057527005672455\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:02:58,097]\u001b[0m Trial 19 finished with value: 0.01278651412576437 and parameters: {'learning rate': 0.0009474621423675804, 'mask initialisation value': 0.995270183172774, 'lambda1': 0.0004305530563037622}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.7350566387176514\n",
      "epoch  1000 / 5000 ...    loss: 0.43300801515579224\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:08:26,615]\u001b[0m Trial 20 finished with value: 422725.875 and parameters: {'learning rate': 0.0008237122652949285, 'mask initialisation value': 0.8577686237389728, 'lambda1': 0.04454116050677203}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.07787415385246277\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:09:04,804]\u001b[0m Trial 21 finished with value: 10083560448.0 and parameters: {'learning rate': 0.011357055684131541, 'mask initialisation value': 0.9955113623887377, 'lambda1': 0.0017352334604785356}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.4983668029308319\n",
      "epoch  1000 / 5000 ...    loss: 0.17944002151489258\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:14:25,460]\u001b[0m Trial 22 finished with value: 0.17620033025741577 and parameters: {'learning rate': 0.0011494130869258586, 'mask initialisation value': 0.8710163712449162, 'lambda1': 0.011833103160331062}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.14268845319747925\n",
      "epoch  1000 / 5000 ...    loss: 0.13748499751091003\n",
      "epoch  2000 / 5000 ...    loss: 0.13254117965698242\n",
      "epoch  3000 / 5000 ...    loss: 0.12784205377101898\n",
      "epoch  4000 / 5000 ...    loss: 0.12334898114204407\n",
      "\u001b[32m[I 2021-08-09 22:35:10,227]\u001b[0m Trial 23 finished with value: 0.11904104053974152 and parameters: {'learning rate': 6.5773181970635075e-06, 'mask initialisation value': 0.7158832843807664, 'lambda1': 0.0016663649093404999}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6675444841384888\n",
      "epoch  1000 / 5000 ...    loss: 0.30115067958831787\n",
      "epoch  2000 / 5000 ...    loss: 1.0156309604644775\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:47:22,873]\u001b[0m Trial 24 finished with value: 0.24775591492652893 and parameters: {'learning rate': 0.00047333707243266143, 'mask initialisation value': 0.5463361805936557, 'lambda1': 0.02194317208575567}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.36881589889526367\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:49:00,037]\u001b[0m Trial 25 finished with value: 0.14990051090717316 and parameters: {'learning rate': 0.006279478213229038, 'mask initialisation value': 0.9857574104230611, 'lambda1': 0.008355582854292356}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.2521169185638428\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 22:49:15,523]\u001b[0m Trial 26 finished with value: 0.5595933198928833 and parameters: {'learning rate': 0.040372520071023967, 'mask initialisation value': 0.7996957050224907, 'lambda1': 0.03359849452086492}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.4303232431411743\n",
      "epoch  1000 / 5000 ...    loss: 0.32843390107154846\n",
      "epoch  2000 / 5000 ...    loss: 0.2631272077560425\n",
      "epoch  3000 / 5000 ...    loss: 0.2314186841249466\n",
      "epoch  4000 / 5000 ...    loss: 0.22470830380916595\n",
      "\u001b[32m[I 2021-08-09 23:10:02,651]\u001b[0m Trial 27 finished with value: 1.3012442588806152 and parameters: {'learning rate': 0.0001020028558830157, 'mask initialisation value': 0.28896321774966277, 'lambda1': 0.017523648068294366}. Best is trial 19 with value: 0.01278651412576437.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.037441253662109375\n",
      "epoch  1000 / 5000 ...    loss: 0.005451599135994911\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 23:14:23,150]\u001b[0m Trial 28 finished with value: 0.005443706642836332 and parameters: {'learning rate': 0.0016286820774752014, 'mask initialisation value': 0.9093594103629556, 'lambda1': 0.00016887885819126747}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 2.506200075149536\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 23:17:07,610]\u001b[0m Trial 29 finished with value: 1859275.375 and parameters: {'learning rate': 0.0016278206513776177, 'mask initialisation value': 0.9245163643186552, 'lambda1': 0.06073398718780728}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5478231906890869\n",
      "epoch  1000 / 5000 ...    loss: 0.3923322558403015\n",
      "epoch  2000 / 5000 ...    loss: 0.25813427567481995\n",
      "epoch  3000 / 5000 ...    loss: 0.19233150780200958\n",
      "epoch  4000 / 5000 ...    loss: 0.18897977471351624\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 23:33:52,488]\u001b[0m Trial 30 finished with value: 0.18897652626037598 and parameters: {'learning rate': 0.00036451573843249244, 'mask initialisation value': 0.99545310175776, 'lambda1': 0.01242134095317745}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.21111519634723663\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 23:37:01,336]\u001b[0m Trial 31 finished with value: 0.12992814183235168 and parameters: {'learning rate': 0.004428675950779165, 'mask initialisation value': 0.9037473770432187, 'lambda1': 0.004474014409009373}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.1415495127439499\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-09 23:37:15,051]\u001b[0m Trial 32 finished with value: 17377421312.0 and parameters: {'learning rate': 0.008228564834874117, 'mask initialisation value': 0.6602868044322111, 'lambda1': 0.0012177744474884528}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.9353732466697693\n",
      "epoch  1000 / 5000 ...    loss: 0.8411620855331421\n",
      "epoch  2000 / 5000 ...    loss: 0.7676353454589844\n",
      "epoch  3000 / 5000 ...    loss: 0.7005115151405334\n",
      "epoch  4000 / 5000 ...    loss: 0.6355360746383667\n",
      "\u001b[32m[I 2021-08-09 23:58:04,204]\u001b[0m Trial 33 finished with value: 0.5718904137611389 and parameters: {'learning rate': 7.230609056321121e-05, 'mask initialisation value': 0.7680742830833415, 'lambda1': 0.025366769881626592}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.3114508390426636\n",
      "epoch  1000 / 5000 ...    loss: 0.14804361760616302\n",
      "epoch  2000 / 5000 ...    loss: 0.12047526240348816\n",
      "epoch  3000 / 5000 ...    loss: 0.11901791393756866\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 00:10:53,966]\u001b[0m Trial 34 finished with value: 0.1190028041601181 and parameters: {'learning rate': 0.0006627090639421669, 'mask initialisation value': 0.8318020191164394, 'lambda1': 0.006970416672743521}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.7307956218719482\n",
      "epoch  1000 / 5000 ...    loss: 0.6585155725479126\n",
      "epoch  2000 / 5000 ...    loss: 0.603993833065033\n",
      "epoch  3000 / 5000 ...    loss: 0.5571895837783813\n",
      "epoch  4000 / 5000 ...    loss: 0.5134804844856262\n",
      "\u001b[32m[I 2021-08-10 00:31:42,339]\u001b[0m Trial 35 finished with value: 0.4714164137840271 and parameters: {'learning rate': 6.292908320035387e-05, 'mask initialisation value': 0.7417737122242449, 'lambda1': 0.01978583483587658}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 2.2370266914367676\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 00:33:31,174]\u001b[0m Trial 36 finished with value: 0.36165958642959595 and parameters: {'learning rate': 0.0015060356547292283, 'mask initialisation value': 0.5620727244336801, 'lambda1': 0.08471039483500395}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.468044251203537\n",
      "epoch  1000 / 5000 ...    loss: 0.341124027967453\n",
      "epoch  2000 / 5000 ...    loss: 0.2707765996456146\n",
      "epoch  3000 / 5000 ...    loss: 0.21854494512081146\n",
      "epoch  4000 / 5000 ...    loss: 0.18832910060882568\n",
      "\u001b[32m[I 2021-08-10 00:54:17,966]\u001b[0m Trial 37 finished with value: 0.17972788214683533 and parameters: {'learning rate': 0.00017718738904079067, 'mask initialisation value': 0.6673296453962662, 'lambda1': 0.01234789478905408}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 / 5000 ...    loss: 0.03738575801253319\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 00:57:52,825]\u001b[0m Trial 38 finished with value: 141.90756225585938 and parameters: {'learning rate': 0.0029695189454789998, 'mask initialisation value': 0.9133163377692286, 'lambda1': 0.00019890140087529373}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.7529940605163574\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 00:58:11,253]\u001b[0m Trial 39 finished with value: 0.3653925657272339 and parameters: {'learning rate': 0.02430136690672181, 'mask initialisation value': 0.4932168121547238, 'lambda1': 0.02756108932158402}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.4707359075546265\n",
      "epoch  1000 / 5000 ...    loss: 0.8261221647262573\n",
      "epoch  2000 / 5000 ...    loss: 0.35640567541122437\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:10:38,432]\u001b[0m Trial 40 finished with value: 0.32575422525405884 and parameters: {'learning rate': 0.0004267480637146621, 'mask initialisation value': 0.815021004016176, 'lambda1': 0.039168534055983036}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.35808107256889343\n",
      "epoch  1000 / 5000 ...    loss: 0.15802457928657532\n",
      "epoch  2000 / 5000 ...    loss: 0.1354973167181015\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:20:37,199]\u001b[0m Trial 41 finished with value: 0.13498923182487488 and parameters: {'learning rate': 0.0007513918641109403, 'mask initialisation value': 0.8318681474414783, 'lambda1': 0.00823925582738626}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.24373699724674225\n",
      "epoch  1000 / 5000 ...    loss: 0.12432156503200531\n",
      "epoch  2000 / 5000 ...    loss: 0.10027257353067398\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:31:33,899]\u001b[0m Trial 42 finished with value: 0.09982208907604218 and parameters: {'learning rate': 0.0007445856575555352, 'mask initialisation value': 0.9574534504646324, 'lambda1': 0.005416246102577161}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.20473702251911163\n",
      "epoch  1000 / 5000 ...    loss: 0.08714579045772552\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:37:02,633]\u001b[0m Trial 43 finished with value: 0.08684352785348892 and parameters: {'learning rate': 0.0019776144746511603, 'mask initialisation value': 0.9606129644330924, 'lambda1': 0.004504643297487859}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5702298283576965\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:39:56,429]\u001b[0m Trial 44 finished with value: 0.19579428434371948 and parameters: {'learning rate': 0.0022557950311863535, 'mask initialisation value': 0.8864030418384381, 'lambda1': 0.013588711186267678}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.027139786630868912\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:41:26,322]\u001b[0m Trial 45 finished with value: 0.012432483956217766 and parameters: {'learning rate': 0.0057969073285463425, 'mask initialisation value': 0.9668610976959414, 'lambda1': 0.00036745272803708753}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.12243636697530746\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:43:36,549]\u001b[0m Trial 46 finished with value: 10013740032.0 and parameters: {'learning rate': 0.004382912132611308, 'mask initialisation value': 0.6443231452428309, 'lambda1': 0.0004171963986672182}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.4194093644618988\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:44:06,760]\u001b[0m Trial 47 finished with value: 0.1776466965675354 and parameters: {'learning rate': 0.019824125596645, 'mask initialisation value': 0.7561247144724581, 'lambda1': 0.010215004555447925}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6493185758590698\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:45:02,980]\u001b[0m Trial 48 finished with value: 963273.75 and parameters: {'learning rate': 0.007335646970916747, 'mask initialisation value': 0.8527608469266416, 'lambda1': 0.015940846478667746}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.2009390890598297\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 01:45:20,136]\u001b[0m Trial 49 finished with value: 0.3461745083332062 and parameters: {'learning rate': 0.09940789707108323, 'mask initialisation value': 0.9996468407556849, 'lambda1': 0.004547337005125881}. Best is trial 28 with value: 0.005443706642836332.\u001b[0m\n",
      "Done\n",
      "all plots saved in /home/jupyter/profiles/tko/bachelor thesis/proloaf/./oracles/interpretation/opsd_GRU_gnll_opsd_fh24_onehot_ssr/plots/\n",
      "Elapsed time:  26808.80113902688\n",
      "\n",
      "\n",
      "timestep:  304\n",
      "create saliency maps...\n",
      "epoch  0 / 5000 ...    loss: 0.8681542277336121\n",
      "epoch  1000 / 5000 ...    loss: 0.8508290648460388\n",
      "epoch  2000 / 5000 ...    loss: 0.8333699703216553\n",
      "epoch  3000 / 5000 ...    loss: 0.8158578872680664\n",
      "epoch  4000 / 5000 ...    loss: 0.7985990643501282\n",
      "\u001b[32m[I 2021-08-10 02:06:08,509]\u001b[0m Trial 0 finished with value: 0.7818068265914917 and parameters: {'learning rate': 7.99486217053616e-06, 'mask initialisation value': 0.7386326710961899, 'lambda1': 0.02124877285372905}. Best is trial 0 with value: 0.7818068265914917.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 3.7009658813476562\n",
      "epoch  1000 / 5000 ...    loss: 3.6759321689605713\n",
      "epoch  2000 / 5000 ...    loss: 3.6510541439056396\n",
      "epoch  3000 / 5000 ...    loss: 3.626314401626587\n",
      "epoch  4000 / 5000 ...    loss: 3.6018221378326416\n",
      "\u001b[32m[I 2021-08-10 02:27:01,310]\u001b[0m Trial 1 finished with value: 3.577521800994873 and parameters: {'learning rate': 4.827859075447374e-06, 'mask initialisation value': 0.8128104755431463, 'lambda1': 0.09966022726616267}. Best is trial 0 with value: 0.7818068265914917.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.70670485496521\n",
      "epoch  1000 / 5000 ...    loss: 0.7030723690986633\n",
      "epoch  2000 / 5000 ...    loss: 0.6994335055351257\n",
      "epoch  3000 / 5000 ...    loss: 0.6957770586013794\n",
      "epoch  4000 / 5000 ...    loss: 0.6921142339706421\n",
      "\u001b[32m[I 2021-08-10 02:47:53,778]\u001b[0m Trial 2 finished with value: 0.6884596347808838 and parameters: {'learning rate': 1.934094016744552e-06, 'mask initialisation value': 0.4837755110836206, 'lambda1': 0.01681106153766363}. Best is trial 2 with value: 0.6884596347808838.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8119872212409973\n",
      "epoch  1000 / 5000 ...    loss: 0.8039170503616333\n",
      "epoch  2000 / 5000 ...    loss: 0.7958564758300781\n",
      "epoch  3000 / 5000 ...    loss: 0.7878249883651733\n",
      "epoch  4000 / 5000 ...    loss: 0.7796632647514343\n",
      "\u001b[32m[I 2021-08-10 03:08:40,649]\u001b[0m Trial 3 finished with value: 0.7714969515800476 and parameters: {'learning rate': 3.820012097792273e-06, 'mask initialisation value': 0.6876031098939029, 'lambda1': 0.019785354341931263}. Best is trial 2 with value: 0.6884596347808838.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6087155938148499\n",
      "epoch  1000 / 5000 ...    loss: 0.5433516502380371\n",
      "epoch  2000 / 5000 ...    loss: 0.5076652765274048\n",
      "epoch  3000 / 5000 ...    loss: 0.4553293287754059\n",
      "epoch  4000 / 5000 ...    loss: 0.402818500995636\n",
      "\u001b[32m[I 2021-08-10 03:29:25,887]\u001b[0m Trial 4 finished with value: 0.3662472367286682 and parameters: {'learning rate': 0.00013224583497667414, 'mask initialisation value': 0.02532694202956831, 'lambda1': 0.039622076542079866}. Best is trial 4 with value: 0.3662472367286682.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.0145049095153809\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 03:33:17,796]\u001b[0m Trial 5 finished with value: 101.01998901367188 and parameters: {'learning rate': 0.0016475762003352909, 'mask initialisation value': 0.9610461963409935, 'lambda1': 0.023344711878597924}. Best is trial 4 with value: 0.3662472367286682.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8547124862670898\n",
      "epoch  1000 / 5000 ...    loss: 0.30144327878952026\n",
      "epoch  2000 / 5000 ...    loss: 191119.890625\n",
      "epoch  3000 / 5000 ...    loss: 0.2730681300163269\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 03:47:41,979]\u001b[0m Trial 6 finished with value: 0.2726406753063202 and parameters: {'learning rate': 0.00047218703138081645, 'mask initialisation value': 0.367795029816988, 'lambda1': 0.027151330687661058}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 3.2460134029388428\n",
      "epoch  1000 / 5000 ...    loss: 2.6898696422576904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2000 / 5000 ...    loss: 2.211576461791992\n",
      "epoch  3000 / 5000 ...    loss: 1.7510623931884766\n",
      "epoch  4000 / 5000 ...    loss: 1.3038145303726196\n",
      "\u001b[32m[I 2021-08-10 04:08:29,634]\u001b[0m Trial 7 finished with value: 0.8898212909698486 and parameters: {'learning rate': 0.00012343300067707664, 'mask initialisation value': 0.7459860144604153, 'lambda1': 0.09334886100158105}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 2.2603743076324463\n",
      "epoch  1000 / 5000 ...    loss: 2.2547717094421387\n",
      "epoch  2000 / 5000 ...    loss: 2.2491912841796875\n",
      "epoch  3000 / 5000 ...    loss: 2.2435860633850098\n",
      "epoch  4000 / 5000 ...    loss: 2.237997531890869\n",
      "\u001b[32m[I 2021-08-10 04:29:17,727]\u001b[0m Trial 8 finished with value: 2.2324109077453613 and parameters: {'learning rate': 1.1976276421418906e-06, 'mask initialisation value': 0.4601464794523421, 'lambda1': 0.09339622140373123}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5881145000457764\n",
      "epoch  1000 / 5000 ...    loss: 0.5723010897636414\n",
      "epoch  2000 / 5000 ...    loss: 0.5596948862075806\n",
      "epoch  3000 / 5000 ...    loss: 0.550309419631958\n",
      "epoch  4000 / 5000 ...    loss: 0.5429009795188904\n",
      "\u001b[32m[I 2021-08-10 04:50:04,875]\u001b[0m Trial 9 finished with value: 0.5366111397743225 and parameters: {'learning rate': 9.093284064703144e-06, 'mask initialisation value': 0.933300182775197, 'lambda1': 0.013279267543688923}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.0548663139343262\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 04:50:19,765]\u001b[0m Trial 10 finished with value: 1.4166016578674316 and parameters: {'learning rate': 0.08429044308820637, 'mask initialisation value': 0.2016966608336041, 'lambda1': 0.0631302037668994}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5766820311546326\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 04:50:24,935]\u001b[0m Trial 11 finished with value: 0.5756670832633972 and parameters: {'learning rate': 0.0006506405974610709, 'mask initialisation value': 0.0014771108463226441, 'lambda1': 0.048265428376342165}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.814971387386322\n",
      "epoch  1000 / 5000 ...    loss: 0.6548875570297241\n",
      "epoch  2000 / 5000 ...    loss: 0.5318910479545593\n",
      "epoch  3000 / 5000 ...    loss: 0.4819551110267639\n",
      "epoch  4000 / 5000 ...    loss: 0.4571511745452881\n",
      "\u001b[32m[I 2021-08-10 05:11:10,998]\u001b[0m Trial 12 finished with value: 0.43339601159095764 and parameters: {'learning rate': 7.088281753937927e-05, 'mask initialisation value': 0.1679004318067423, 'lambda1': 0.041546571531645295}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.3449715375900269\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:11:28,415]\u001b[0m Trial 13 finished with value: 0.4989852011203766 and parameters: {'learning rate': 0.007596690652890847, 'mask initialisation value': 0.30473288894768236, 'lambda1': 0.06682413371223012}. Best is trial 6 with value: 0.2726406753063202.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5646915435791016\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:13:50,075]\u001b[0m Trial 14 finished with value: 0.10977722704410553 and parameters: {'learning rate': 0.00485983420276586, 'mask initialisation value': 0.029415348957031746, 'lambda1': 0.0014540917579575555}. Best is trial 14 with value: 0.10977722704410553.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.4502803087234497\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:14:48,242]\u001b[0m Trial 15 finished with value: 10011004928.0 and parameters: {'learning rate': 0.014084983139748899, 'mask initialisation value': 0.35740991175852144, 'lambda1': 0.0019830575229244102}. Best is trial 14 with value: 0.10977722704410553.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5404826402664185\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:18:18,572]\u001b[0m Trial 16 finished with value: 0.10855664312839508 and parameters: {'learning rate': 0.0034841768819376282, 'mask initialisation value': 0.11559572400621232, 'lambda1': 0.002342111233313725}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5431481003761292\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:18:39,462]\u001b[0m Trial 17 finished with value: 31210227712.0 and parameters: {'learning rate': 0.07114104203509801, 'mask initialisation value': 0.12617783995254706, 'lambda1': 0.0034008442827643884}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.551067054271698\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:20:36,917]\u001b[0m Trial 18 finished with value: 1695927.5 and parameters: {'learning rate': 0.006587868705902147, 'mask initialisation value': 0.06122395147035351, 'lambda1': 0.0002743141792615662}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5559110641479492\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:23:27,796]\u001b[0m Trial 19 finished with value: 0.12807273864746094 and parameters: {'learning rate': 0.002141390607844655, 'mask initialisation value': 0.2571528640816034, 'lambda1': 0.007757757531074154}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.1575430631637573\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:23:51,844]\u001b[0m Trial 20 finished with value: 10004717568.0 and parameters: {'learning rate': 0.027864682454096713, 'mask initialisation value': 0.6085205864422495, 'lambda1': 0.03320626393377858}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5703703165054321\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:26:22,133]\u001b[0m Trial 21 finished with value: 0.14173464477062225 and parameters: {'learning rate': 0.0022065953198380254, 'mask initialisation value': 0.25599997280160214, 'lambda1': 0.009024583801473075}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.570475161075592\n",
      "epoch  1000 / 5000 ...    loss: 0.16181451082229614\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:31:35,061]\u001b[0m Trial 22 finished with value: 0.1613997370004654 and parameters: {'learning rate': 0.002103259882359547, 'mask initialisation value': 0.08394978559647898, 'lambda1': 0.00786908550226546}. Best is trial 16 with value: 0.10855664312839508.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.4962865710258484\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:33:56,906]\u001b[0m Trial 23 finished with value: 0.06753334403038025 and parameters: {'learning rate': 0.004172582166964279, 'mask initialisation value': 0.19846875685913956, 'lambda1': 0.0002900835502410125}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5323519706726074\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:34:35,617]\u001b[0m Trial 24 finished with value: 0.10734516382217407 and parameters: {'learning rate': 0.0258991999036733, 'mask initialisation value': 0.1266461333631049, 'lambda1': 0.0014930937559415659}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5185118913650513\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:35:03,976]\u001b[0m Trial 25 finished with value: 10053404672.0 and parameters: {'learning rate': 0.03928348896313482, 'mask initialisation value': 0.14344873763097182, 'lambda1': 0.00023079206634441223}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.1517307758331299\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:35:12,659]\u001b[0m Trial 26 finished with value: 0.6143804788589478 and parameters: {'learning rate': 0.02231701409391311, 'mask initialisation value': 0.21869982917749944, 'lambda1': 0.06901308743770543}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5944440364837646\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:35:57,261]\u001b[0m Trial 27 finished with value: 3909068.5 and parameters: {'learning rate': 0.0009767474103096285, 'mask initialisation value': 0.11802325153010772, 'lambda1': 0.012833578868831429}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.939273476600647\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:36:36,963]\u001b[0m Trial 28 finished with value: 0.32614606618881226 and parameters: {'learning rate': 0.010935879276950607, 'mask initialisation value': 0.39356260631792583, 'lambda1': 0.031027015535453957}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5772899389266968\n",
      "stopping...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-10 05:36:41,543]\u001b[0m Trial 29 finished with value: 0.6212486028671265 and parameters: {'learning rate': 0.004527073747652861, 'mask initialisation value': 0.001050115552025388, 'lambda1': 0.07748343764012976}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8131479024887085\n",
      "epoch  1000 / 5000 ...    loss: 0.4324013292789459\n",
      "epoch  2000 / 5000 ...    loss: 0.28769585490226746\n",
      "epoch  3000 / 5000 ...    loss: 0.24507257342338562\n",
      "epoch  4000 / 5000 ...    loss: 388031.0625\n",
      "\u001b[32m[I 2021-08-10 05:57:21,813]\u001b[0m Trial 30 finished with value: 0.23349308967590332 and parameters: {'learning rate': 0.00025622235970027365, 'mask initialisation value': 0.5604637848437501, 'lambda1': 0.020842334483937915}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5643147826194763\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 05:59:44,847]\u001b[0m Trial 31 finished with value: 4434853.5 and parameters: {'learning rate': 0.004168049036951946, 'mask initialisation value': 0.0258144105740159, 'lambda1': 0.00010491839669394447}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.568130373954773\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:00:06,963]\u001b[0m Trial 32 finished with value: 0.1969185769557953 and parameters: {'learning rate': 0.04875930180873566, 'mask initialisation value': 0.09011416923424752, 'lambda1': 0.007361363677444464}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6168950796127319\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:00:32,330]\u001b[0m Trial 33 finished with value: 6320923.5 and parameters: {'learning rate': 0.01803814777380737, 'mask initialisation value': 0.1750377600524729, 'lambda1': 0.014628625010318135}. Best is trial 23 with value: 0.06753334403038025.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.4553503692150116\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:04:21,768]\u001b[0m Trial 34 finished with value: 0.023857353255152702 and parameters: {'learning rate': 0.00441663224309063, 'mask initialisation value': 0.2932110423195451, 'lambda1': 0.0003412240204761028}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6579950451850891\n",
      "epoch  1000 / 5000 ...    loss: 0.2066679298877716\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:11:54,485]\u001b[0m Trial 35 finished with value: 0.20294705033302307 and parameters: {'learning rate': 0.0010545657417753164, 'mask initialisation value': 0.2716754906254711, 'lambda1': 0.016406967668668358}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.528008759021759\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:13:01,792]\u001b[0m Trial 36 finished with value: 0.11139465868473053 and parameters: {'learning rate': 0.010043845099950195, 'mask initialisation value': 0.3177558760730872, 'lambda1': 0.006342522897968682}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8197535276412964\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:15:39,794]\u001b[0m Trial 37 finished with value: 0.2617354989051819 and parameters: {'learning rate': 0.003348480529409891, 'mask initialisation value': 0.400847424030922, 'lambda1': 0.02393835886451623}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.605323314666748\n",
      "epoch  1000 / 5000 ...    loss: 294764.78125\n",
      "epoch  2000 / 5000 ...    loss: 0.19283924996852875\n",
      "epoch  3000 / 5000 ...    loss: 0.177130326628685\n",
      "epoch  4000 / 5000 ...    loss: 0.1729775071144104\n",
      "\u001b[32m[I 2021-08-10 06:36:20,556]\u001b[0m Trial 38 finished with value: 0.17188537120819092 and parameters: {'learning rate': 0.00031464186966115044, 'mask initialisation value': 0.23509129854161365, 'lambda1': 0.01228726260243019}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.7205014228820801\n",
      "epoch  1000 / 5000 ...    loss: 285272.1875\n",
      "epoch  2000 / 5000 ...    loss: 0.2116803377866745\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:44:48,475]\u001b[0m Trial 39 finished with value: 0.21166586875915527 and parameters: {'learning rate': 0.0011289324550808296, 'mask initialisation value': 0.46338542552252193, 'lambda1': 0.01761609566297334}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8188782930374146\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:45:04,851]\u001b[0m Trial 40 finished with value: 1.0690979957580566 and parameters: {'learning rate': 0.09891816842108068, 'mask initialisation value': 0.3176248655648215, 'lambda1': 0.02706996038503573}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5531991124153137\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:47:11,244]\u001b[0m Trial 41 finished with value: 0.09523671120405197 and parameters: {'learning rate': 0.006291671397971394, 'mask initialisation value': 0.05751707600414632, 'lambda1': 0.0005538459250115752}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5383548736572266\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:47:34,707]\u001b[0m Trial 42 finished with value: 38997932.0 and parameters: {'learning rate': 0.030347980155155822, 'mask initialisation value': 0.1868184171096529, 'lambda1': 0.004799116434369978}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5518909692764282\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:48:36,152]\u001b[0m Trial 43 finished with value: 0.09369408339262009 and parameters: {'learning rate': 0.011836929615019637, 'mask initialisation value': 0.06040119578892099, 'lambda1': 0.0004647153070197619}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5809624791145325\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:49:09,383]\u001b[0m Trial 44 finished with value: 19269968.0 and parameters: {'learning rate': 0.015136351224719206, 'mask initialisation value': 0.060429392580206485, 'lambda1': 0.011358575520857263}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5129162669181824\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:50:51,121]\u001b[0m Trial 45 finished with value: 0.07672125101089478 and parameters: {'learning rate': 0.007778054748510162, 'mask initialisation value': 0.1562479393927995, 'lambda1': 0.0001739234121420874}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.6576770544052124\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:52:29,373]\u001b[0m Trial 46 finished with value: 0.23913109302520752 and parameters: {'learning rate': 0.006889105537018895, 'mask initialisation value': 0.19383611440209242, 'lambda1': 0.01891166299941722}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5774911046028137\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 06:53:26,815]\u001b[0m Trial 47 finished with value: 0.18803617358207703 and parameters: {'learning rate': 0.009950413174236396, 'mask initialisation value': 0.05080140274213941, 'lambda1': 0.010269780443487813}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8763172626495361\n",
      "epoch  1000 / 5000 ...    loss: 0.8211705088615417\n",
      "epoch  2000 / 5000 ...    loss: 0.7679933905601501\n",
      "epoch  3000 / 5000 ...    loss: 0.716988742351532\n",
      "epoch  4000 / 5000 ...    loss: 0.6686172485351562\n",
      "\u001b[32m[I 2021-08-10 07:14:06,401]\u001b[0m Trial 48 finished with value: 0.6236961483955383 and parameters: {'learning rate': 1.98133744645929e-05, 'mask initialisation value': 0.15691371993489373, 'lambda1': 0.05263717490537898}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5579317808151245\n",
      "epoch  1000 / 5000 ...    loss: 0.13511843979358673\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 07:20:56,801]\u001b[0m Trial 49 finished with value: 0.13250869512557983 and parameters: {'learning rate': 0.0014525573352234427, 'mask initialisation value': 0.08649186332454728, 'lambda1': 0.004621270814426883}. Best is trial 34 with value: 0.023857353255152702.\u001b[0m\n",
      "Done\n",
      "all plots saved in /home/jupyter/profiles/tko/bachelor thesis/proloaf/./oracles/interpretation/opsd_GRU_gnll_opsd_fh24_onehot_ssr/plots/\n",
      "Elapsed time:  20136.6384967193\n",
      "\n",
      "\n",
      "timestep:  25720\n",
      "create saliency maps...\n",
      "epoch  0 / 5000 ...    loss: 2.1037099361419678\n",
      "epoch  1000 / 5000 ...    loss: 2.078151226043701\n",
      "epoch  2000 / 5000 ...    loss: 2.0527148246765137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3000 / 5000 ...    loss: 2.0273945331573486\n",
      "epoch  4000 / 5000 ...    loss: 2.002169132232666\n",
      "\u001b[32m[I 2021-08-10 07:41:43,075]\u001b[0m Trial 0 finished with value: 1.9770547151565552 and parameters: {'learning rate': 5.943945074585406e-06, 'mask initialisation value': 0.45712615078341723, 'lambda1': 0.09807206350884405}. Best is trial 0 with value: 1.9770547151565552.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5553535223007202\n",
      "epoch  1000 / 5000 ...    loss: 0.5507488250732422\n",
      "epoch  2000 / 5000 ...    loss: 0.5462436676025391\n",
      "epoch  3000 / 5000 ...    loss: 0.5418307185173035\n",
      "epoch  4000 / 5000 ...    loss: 0.5374950170516968\n",
      "\u001b[32m[I 2021-08-10 08:02:29,562]\u001b[0m Trial 1 finished with value: 0.533233642578125 and parameters: {'learning rate': 3.988537296892586e-06, 'mask initialisation value': 0.5826159199801726, 'lambda1': 0.01790306674005251}. Best is trial 1 with value: 0.533233642578125.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.1295781135559082\n",
      "epoch  1000 / 5000 ...    loss: 1150181.875\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 08:07:40,351]\u001b[0m Trial 2 finished with value: 0.24974891543388367 and parameters: {'learning rate': 0.0003385527246880522, 'mask initialisation value': 0.34641295855777365, 'lambda1': 0.06407957293973084}. Best is trial 2 with value: 0.24974891543388367.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.25427690148353577\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 08:08:04,151]\u001b[0m Trial 3 finished with value: 0.1100534200668335 and parameters: {'learning rate': 0.01798845533858001, 'mask initialisation value': 0.4934572140819369, 'lambda1': 0.006396364253042342}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.9343746900558472\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 08:10:00,062]\u001b[0m Trial 4 finished with value: 0.25523123145103455 and parameters: {'learning rate': 0.0009737727856256248, 'mask initialisation value': 0.3351800099943073, 'lambda1': 0.05286540659802105}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.7216201424598694\n",
      "epoch  1000 / 5000 ...    loss: 0.7196866273880005\n",
      "epoch  2000 / 5000 ...    loss: 0.7177634835243225\n",
      "epoch  3000 / 5000 ...    loss: 0.7158488035202026\n",
      "epoch  4000 / 5000 ...    loss: 0.7139385938644409\n",
      "\u001b[32m[I 2021-08-10 08:30:48,028]\u001b[0m Trial 5 finished with value: 0.712036669254303 and parameters: {'learning rate': 1.1006745245337163e-06, 'mask initialisation value': 0.390929986559314, 'lambda1': 0.03376400823956525}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.33265548944473267\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 08:31:38,212]\u001b[0m Trial 6 finished with value: 0.1905112862586975 and parameters: {'learning rate': 0.002099407325498016, 'mask initialisation value': 0.19734159734646217, 'lambda1': 0.016951088978764108}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 2.367981433868408\n",
      "epoch  1000 / 5000 ...    loss: 2.35752272605896\n",
      "epoch  2000 / 5000 ...    loss: 2.347169876098633\n",
      "epoch  3000 / 5000 ...    loss: 2.336862802505493\n",
      "epoch  4000 / 5000 ...    loss: 2.3266079425811768\n",
      "\u001b[32m[I 2021-08-10 08:52:24,992]\u001b[0m Trial 7 finished with value: 2.316410779953003 and parameters: {'learning rate': 3.3732876422131887e-06, 'mask initialisation value': 0.7625866034933512, 'lambda1': 0.06868785288433264}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.1077790260314941\n",
      "epoch  1000 / 5000 ...    loss: 1.0700044631958008\n",
      "epoch  2000 / 5000 ...    loss: 1.034650206565857\n",
      "epoch  3000 / 5000 ...    loss: 1.000945806503296\n",
      "epoch  4000 / 5000 ...    loss: 0.9683982729911804\n",
      "\u001b[32m[I 2021-08-10 09:13:10,473]\u001b[0m Trial 8 finished with value: 0.9367018938064575 and parameters: {'learning rate': 2.2835545683358235e-05, 'mask initialisation value': 0.6911151727310877, 'lambda1': 0.03399054966833981}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.734850287437439\n",
      "epoch  1000 / 5000 ...    loss: 0.7317776679992676\n",
      "epoch  2000 / 5000 ...    loss: 0.7287231683731079\n",
      "epoch  3000 / 5000 ...    loss: 0.7256734371185303\n",
      "epoch  4000 / 5000 ...    loss: 0.7226431369781494\n",
      "\u001b[32m[I 2021-08-10 09:33:56,817]\u001b[0m Trial 9 finished with value: 0.7196229100227356 and parameters: {'learning rate': 1.4891029141015805e-06, 'mask initialisation value': 0.31382226098539967, 'lambda1': 0.041706798071815425}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.243414968252182\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 09:34:42,130]\u001b[0m Trial 10 finished with value: 14628310016.0 and parameters: {'learning rate': 0.07000502616098633, 'mask initialisation value': 0.9277019055744007, 'lambda1': 0.005534888087944008}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.2269297093153\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 09:35:23,108]\u001b[0m Trial 11 finished with value: 94150208.0 and parameters: {'learning rate': 0.015571082746159825, 'mask initialisation value': 0.06417828164478656, 'lambda1': 0.002748562500839157}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.2585488259792328\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 09:37:24,454]\u001b[0m Trial 12 finished with value: 0.18459534645080566 and parameters: {'learning rate': 0.003768577895012768, 'mask initialisation value': 0.05097856650432911, 'lambda1': 0.015932567210416356}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.23776854574680328\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 09:38:08,908]\u001b[0m Trial 13 finished with value: 0.17585104703903198 and parameters: {'learning rate': 0.011161355139466415, 'mask initialisation value': 0.004840029306986959, 'lambda1': 0.012420180297584581}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.028963210061192513\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 09:38:37,383]\u001b[0m Trial 14 finished with value: 34939108.0 and parameters: {'learning rate': 0.039737589030800775, 'mask initialisation value': 0.9986555874655065, 'lambda1': 0.0006495395806859943}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.38644149899482727\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 09:38:50,874]\u001b[0m Trial 15 finished with value: 0.24894312024116516 and parameters: {'learning rate': 0.012183860381737495, 'mask initialisation value': 0.17084332783065834, 'lambda1': 0.02582352878124486}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 3.195542097091675\n",
      "epoch  1000 / 5000 ...    loss: 2.978731870651245\n",
      "epoch  2000 / 5000 ...    loss: 2.7664906978607178\n",
      "epoch  3000 / 5000 ...    loss: 2.5546815395355225\n",
      "epoch  4000 / 5000 ...    loss: 2.342898368835449\n",
      "\u001b[32m[I 2021-08-10 09:59:32,725]\u001b[0m Trial 16 finished with value: 2.1313321590423584 and parameters: {'learning rate': 5.9225455220095935e-05, 'mask initialisation value': 0.8328577764410853, 'lambda1': 0.08581415763499019}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.3201899528503418\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 10:00:09,613]\u001b[0m Trial 17 finished with value: 0.13423973321914673 and parameters: {'learning rate': 0.011347600455926077, 'mask initialisation value': 0.5816516433580139, 'lambda1': 0.008772405427015982}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 1.3766857385635376\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 10:00:18,829]\u001b[0m Trial 18 finished with value: 0.9061841368675232 and parameters: {'learning rate': 0.09125139382312611, 'mask initialisation value': 0.5889353486092841, 'lambda1': 0.04933495572693166}. Best is trial 3 with value: 0.1100534200668335.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.11501426994800568\n",
      "epoch  1000 / 5000 ...    loss: 0.025536689907312393\n",
      "epoch  2000 / 5000 ...    loss: 0.015889430418610573\n",
      "epoch  3000 / 5000 ...    loss: 0.014170641079545021\n",
      "epoch  4000 / 5000 ...    loss: 0.013721323572099209\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 10:19:35,908]\u001b[0m Trial 19 finished with value: 0.013593373820185661 and parameters: {'learning rate': 0.00041685633775105164, 'mask initialisation value': 0.5588936069466511, 'lambda1': 0.0006097966708777198}. Best is trial 19 with value: 0.013593373820185661.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.7438727617263794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1000 / 5000 ...    loss: 0.5787200331687927\n",
      "epoch  2000 / 5000 ...    loss: 0.4446485638618469\n",
      "epoch  3000 / 5000 ...    loss: 0.33000922203063965\n",
      "epoch  4000 / 5000 ...    loss: 0.25125861167907715\n",
      "\u001b[32m[I 2021-08-10 10:40:19,439]\u001b[0m Trial 20 finished with value: 112594.3984375 and parameters: {'learning rate': 0.00012527731467673028, 'mask initialisation value': 0.49016014966579424, 'lambda1': 0.029014887890010672}. Best is trial 19 with value: 0.013593373820185661.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.11381838470697403\n",
      "epoch  1000 / 5000 ...    loss: 0.024414384737610817\n",
      "epoch  2000 / 5000 ...    loss: 0.021746885031461716\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 10:51:20,042]\u001b[0m Trial 21 finished with value: 0.021491268649697304 and parameters: {'learning rate': 0.0006764598960772361, 'mask initialisation value': 0.6178554754312644, 'lambda1': 0.0009995249509102255}. Best is trial 19 with value: 0.013593373820185661.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.07962195575237274\n",
      "epoch  1000 / 5000 ...    loss: 0.01174249779433012\n",
      "epoch  2000 / 5000 ...    loss: 0.00789006520062685\n",
      "epoch  3000 / 5000 ...    loss: 0.007167012430727482\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 11:04:56,929]\u001b[0m Trial 22 finished with value: 0.007089005783200264 and parameters: {'learning rate': 0.0004408546301309333, 'mask initialisation value': 0.688046331206759, 'lambda1': 0.00029380375061197604}. Best is trial 22 with value: 0.007089005783200264.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.08657244592905045\n",
      "epoch  1000 / 5000 ...    loss: 0.01745474711060524\n",
      "epoch  2000 / 5000 ...    loss: 0.01374808419495821\n",
      "epoch  3000 / 5000 ...    loss: 0.013163149356842041\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 11:19:15,631]\u001b[0m Trial 23 finished with value: 0.013064463622868061 and parameters: {'learning rate': 0.000489242873520452, 'mask initialisation value': 0.6964209349778153, 'lambda1': 0.0005773676238630052}. Best is trial 22 with value: 0.007089005783200264.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.0682450532913208\n",
      "epoch  1000 / 5000 ...    loss: 0.026443995535373688\n",
      "epoch  2000 / 5000 ...    loss: 0.012909673154354095\n",
      "epoch  3000 / 5000 ...    loss: 0.008412067778408527\n",
      "epoch  4000 / 5000 ...    loss: 0.00648894626647234\n",
      "\u001b[32m[I 2021-08-10 11:39:59,384]\u001b[0m Trial 24 finished with value: 0.005571491084992886 and parameters: {'learning rate': 0.0001303387897214226, 'mask initialisation value': 0.7275312699060019, 'lambda1': 0.00019976803741314874}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8316944241523743\n",
      "epoch  1000 / 5000 ...    loss: 0.7296823263168335\n",
      "epoch  2000 / 5000 ...    loss: 0.6443274617195129\n",
      "epoch  3000 / 5000 ...    loss: 0.5610252618789673\n",
      "epoch  4000 / 5000 ...    loss: 0.47918927669525146\n",
      "\u001b[32m[I 2021-08-10 12:00:52,837]\u001b[0m Trial 25 finished with value: 0.4001414477825165 and parameters: {'learning rate': 0.00010544945709049783, 'mask initialisation value': 0.8299155456840075, 'lambda1': 0.021625911250586712}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.36076658964157104\n",
      "epoch  1000 / 5000 ...    loss: 0.3432067334651947\n",
      "epoch  2000 / 5000 ...    loss: 0.32886937260627747\n",
      "epoch  3000 / 5000 ...    loss: 0.3167615234851837\n",
      "epoch  4000 / 5000 ...    loss: 0.3062129318714142\n",
      "\u001b[32m[I 2021-08-10 12:21:39,750]\u001b[0m Trial 26 finished with value: 0.2967301607131958 and parameters: {'learning rate': 2.2650807097074705e-05, 'mask initialisation value': 0.7635224217962445, 'lambda1': 0.00910206015492229}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.10169245302677155\n",
      "epoch  1000 / 5000 ...    loss: 0.023074373602867126\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 12:25:51,850]\u001b[0m Trial 27 finished with value: 0.02307954989373684 and parameters: {'learning rate': 0.0015680955122366962, 'mask initialisation value': 0.6934166421509933, 'lambda1': 0.0010514326561148657}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.9689844846725464\n",
      "epoch  1000 / 5000 ...    loss: 0.8024382591247559\n",
      "epoch  2000 / 5000 ...    loss: 0.6499384045600891\n",
      "epoch  3000 / 5000 ...    loss: 0.5015846490859985\n",
      "epoch  4000 / 5000 ...    loss: 0.36454614996910095\n",
      "\u001b[32m[I 2021-08-10 12:46:37,952]\u001b[0m Trial 28 finished with value: 0.26161932945251465 and parameters: {'learning rate': 0.00016984011941729172, 'mask initialisation value': 0.8845995930132684, 'lambda1': 0.024119049381718684}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 3.1808605194091797\n",
      "epoch  1000 / 5000 ...    loss: 3.0614962577819824\n",
      "epoch  2000 / 5000 ...    loss: 2.9439663887023926\n",
      "epoch  3000 / 5000 ...    loss: 2.8272781372070312\n",
      "epoch  4000 / 5000 ...    loss: 2.711030960083008\n",
      "\u001b[32m[I 2021-08-10 13:07:19,931]\u001b[0m Trial 29 finished with value: 2.595127820968628 and parameters: {'learning rate': 2.7860011535159578e-05, 'mask initialisation value': 0.7118881958233912, 'lambda1': 0.09906577230642924}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.3924909830093384\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 13:08:50,066]\u001b[0m Trial 30 finished with value: 0.1480982005596161 and parameters: {'learning rate': 0.004093668483832818, 'mask initialisation value': 0.6571778814897622, 'lambda1': 0.010845126279809152}. Best is trial 24 with value: 0.005571491084992886.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.10795414447784424\n",
      "epoch  1000 / 5000 ...    loss: 0.02181250788271427\n",
      "epoch  2000 / 5000 ...    loss: 0.008707422763109207\n",
      "epoch  3000 / 5000 ...    loss: 36926.4921875\n",
      "epoch  4000 / 5000 ...    loss: 0.0051046134904026985\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 13:28:39,858]\u001b[0m Trial 31 finished with value: 0.00482260761782527 and parameters: {'learning rate': 0.00036361043897831897, 'mask initialisation value': 0.5432015010301839, 'lambda1': 0.00018471533799484024}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.06825848668813705\n",
      "epoch  1000 / 5000 ...    loss: 0.01723634824156761\n",
      "epoch  2000 / 5000 ...    loss: 0.01175614818930626\n",
      "epoch  3000 / 5000 ...    loss: 0.010058684274554253\n",
      "epoch  4000 / 5000 ...    loss: 0.009457005187869072\n",
      "\u001b[32m[I 2021-08-10 13:49:25,380]\u001b[0m Trial 32 finished with value: 0.009221439249813557 and parameters: {'learning rate': 0.00026024239652246026, 'mask initialisation value': 0.7589288544326311, 'lambda1': 0.00040195153508443965}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5401000380516052\n",
      "epoch  1000 / 5000 ...    loss: 0.4015498161315918\n",
      "epoch  2000 / 5000 ...    loss: 0.29843029379844666\n",
      "epoch  3000 / 5000 ...    loss: 0.21283461153507233\n",
      "epoch  4000 / 5000 ...    loss: 0.17417681217193604\n",
      "\u001b[32m[I 2021-08-10 14:10:02,054]\u001b[0m Trial 33 finished with value: 0.1707724928855896 and parameters: {'learning rate': 0.0002253338549354874, 'mask initialisation value': 0.7825754269740788, 'lambda1': 0.01419129364136995}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5010801553726196\n",
      "epoch  1000 / 5000 ...    loss: 0.41390469670295715\n",
      "epoch  2000 / 5000 ...    loss: 0.345893919467926\n",
      "epoch  3000 / 5000 ...    loss: 0.2902895212173462\n",
      "epoch  4000 / 5000 ...    loss: 0.24532154202461243\n",
      "\u001b[32m[I 2021-08-10 14:30:43,893]\u001b[0m Trial 34 finished with value: 0.2145933210849762 and parameters: {'learning rate': 8.149216476777067e-05, 'mask initialisation value': 0.41715482616251864, 'lambda1': 0.020005099362607373}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.2679397463798523\n",
      "epoch  1000 / 5000 ...    loss: 0.2311573028564453\n",
      "epoch  2000 / 5000 ...    loss: 0.20370465517044067\n",
      "epoch  3000 / 5000 ...    loss: 0.1823030263185501\n",
      "epoch  4000 / 5000 ...    loss: 0.16498813033103943\n",
      "\u001b[32m[I 2021-08-10 14:51:22,167]\u001b[0m Trial 35 finished with value: 0.15059995651245117 and parameters: {'learning rate': 5.340181097689082e-05, 'mask initialisation value': 0.5240311019534638, 'lambda1': 0.006913668751141728}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.23430600762367249\n",
      "epoch  1000 / 5000 ...    loss: 0.13351836800575256\n",
      "epoch  2000 / 5000 ...    loss: 0.09910348057746887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3000 / 5000 ...    loss: 0.09029865264892578\n",
      "epoch  4000 / 5000 ...    loss: 0.08872450888156891\n",
      "\u001b[32m[I 2021-08-10 15:12:04,289]\u001b[0m Trial 36 finished with value: 0.08834973722696304 and parameters: {'learning rate': 0.00028716166728530153, 'mask initialisation value': 0.6281171396061258, 'lambda1': 0.0054094223670314275}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 3.0947418212890625\n",
      "epoch  1000 / 5000 ...    loss: 3.065236806869507\n",
      "epoch  2000 / 5000 ...    loss: 3.0366523265838623\n",
      "epoch  3000 / 5000 ...    loss: 3.0083794593811035\n",
      "epoch  4000 / 5000 ...    loss: 2.9801597595214844\n",
      "\u001b[32m[I 2021-08-10 15:32:42,210]\u001b[0m Trial 37 finished with value: 2.9519834518432617 and parameters: {'learning rate': 9.164175072897478e-06, 'mask initialisation value': 0.9461803603672282, 'lambda1': 0.07374240680047336}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 3.3939616680145264\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 15:36:00,894]\u001b[0m Trial 38 finished with value: 0.30019205808639526 and parameters: {'learning rate': 0.001121096083005285, 'mask initialisation value': 0.8533720126771942, 'lambda1': 0.08913758067239816}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.5473089218139648\n",
      "epoch  1000 / 5000 ...    loss: 0.24676084518432617\n",
      "epoch  2000 / 5000 ...    loss: 2200169.5\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 15:44:58,067]\u001b[0m Trial 39 finished with value: 0.1731921136379242 and parameters: {'learning rate': 0.0005923196535916964, 'mask initialisation value': 0.7767464345998514, 'lambda1': 0.014469803835931728}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.8344006538391113\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 15:45:35,593]\u001b[0m Trial 40 finished with value: 53257440.0 and parameters: {'learning rate': 0.0035053694287068967, 'mask initialisation value': 0.44159064913656143, 'lambda1': 0.03627348381324861}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.07763626426458359\n",
      "epoch  1000 / 5000 ...    loss: 0.01417136937379837\n",
      "epoch  2000 / 5000 ...    loss: 0.010280271992087364\n",
      "epoch  3000 / 5000 ...    loss: 0.00957106240093708\n",
      "stopping...\n",
      "\u001b[32m[I 2021-08-10 15:58:45,972]\u001b[0m Trial 41 finished with value: 0.009527131915092468 and parameters: {'learning rate': 0.000422667241804765, 'mask initialisation value': 0.7139984526214415, 'lambda1': 0.0004049627040398516}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.21991482377052307\n",
      "epoch  1000 / 5000 ...    loss: 0.13904696702957153\n",
      "epoch  2000 / 5000 ...    loss: 0.10705410689115524\n",
      "epoch  3000 / 5000 ...    loss: 0.08899761736392975\n",
      "epoch  4000 / 5000 ...    loss: 0.08365754783153534\n",
      "\u001b[32m[I 2021-08-10 16:19:27,765]\u001b[0m Trial 42 finished with value: 0.08252908289432526 and parameters: {'learning rate': 0.0002457361188792221, 'mask initialisation value': 0.7210678866270489, 'lambda1': 0.004917356071058119}. Best is trial 31 with value: 0.00482260761782527.\u001b[0m\n",
      "epoch  0 / 5000 ...    loss: 0.3710831105709076\n",
      "epoch  1000 / 5000 ...    loss: 1082685.625\n"
     ]
    }
   ],
   "source": [
    "!python3 ./source/fc_interpret.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reserver",
   "language": "python",
   "name": "reserver"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
